{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"BERT_multilabel_classification.ipynb","provenance":[{"file_id":"https://github.com/rap12391/transformers_multilabel_toxic/blob/master/toxic_multilabel.ipynb","timestamp":1643213922247}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"m5tUoHe9FRhs"},"source":["## Import Libraries"]},{"cell_type":"code","metadata":{"id":"Dr7BCHS-nIRW","scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644745710448,"user_tz":-60,"elapsed":18470,"user":{"displayName":"Rosa Ryhänen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04493503792992534699"}},"outputId":"5148448d-4162-4f1c-de7d-1d3910b70fbe"},"source":["!pip install transformers\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import torch\n","from torch.nn import BCEWithLogitsLoss, BCELoss\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix, f1_score, accuracy_score\n","import pickle\n","#from transformers import *\n","import transformers\n","from tqdm import tqdm, trange\n","from ast import literal_eval"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n","\u001b[K     |████████████████████████████████| 3.5 MB 35.2 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n","Collecting tokenizers!=0.11.3,>=0.10.1\n","  Downloading tokenizers-0.11.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n","\u001b[K     |████████████████████████████████| 6.8 MB 68.1 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.1)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 72.1 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 4.6 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 64.7 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.4 transformers-4.16.2\n"]}]},{"cell_type":"code","metadata":{"id":"zB5Dij6JuItX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644745741233,"user_tz":-60,"elapsed":27540,"user":{"displayName":"Rosa Ryhänen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04493503792992534699"}},"outputId":"f90f0e12-8ac4-47b6-e18d-bd58d3d87566"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"UhjnJEwKnISB","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a19c061d-6f2f-4dbd-e6ea-70af535c0739","executionInfo":{"status":"ok","timestamp":1644746075063,"user_tz":-60,"elapsed":311,"user":{"displayName":"Rosa Ryhänen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04493503792992534699"}}},"source":["device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found GPU at: /device:GPU:0\n"]}]},{"cell_type":"code","metadata":{"id":"uorMX_zrnISM","scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"a8566e62-4090-4240-de14-7af3c1c3437f","executionInfo":{"status":"ok","timestamp":1644746085972,"user_tz":-60,"elapsed":309,"user":{"displayName":"Rosa Ryhänen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04493503792992534699"}}},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()\n","torch.cuda.get_device_name(0)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Tesla T4'"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"dLcetMjZFjSH"},"source":["## Load and Preprocess Training Data"]},{"cell_type":"markdown","metadata":{"id":"2dal0ggBcYdD"},"source":["Dataset will be tokenized then split into training and validation sets. The validation set will be used to monitor training. For testing a separate test set will be loaded for analysis."]},{"cell_type":"code","source":["train_set = \"/content/drive/My Drive/TFM_Rosa-Maria/multilabel-classification/original-data/train.csv\""],"metadata":{"id":"XSEBjz4EeVRf"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0ecREc7GnISW","scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":895},"outputId":"0f813aa0-dd86-4827-9809-3a16ee42053e","executionInfo":{"status":"ok","timestamp":1644746942922,"user_tz":-60,"elapsed":267,"user":{"displayName":"Rosa Ryhänen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04493503792992534699"}}},"source":["# the file might have to be called train.csv\n","df = pd.read_csv(train_set)\n","df.info()\n","df.head()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1708 entries, 0 to 1707\n","Data columns (total 14 columns):\n"," #   Column                    Non-Null Count  Dtype \n","---  ------                    --------------  ----- \n"," 0   id                        1708 non-null   int64 \n"," 1   comment_text              1708 non-null   object\n"," 2   AMBIENCE#GENERAL          1708 non-null   int64 \n"," 3   DRINKS#PRICES             1708 non-null   int64 \n"," 4   DRINKS#QUALITY            1708 non-null   int64 \n"," 5   DRINKS#STYLE_OPTIONS      1708 non-null   int64 \n"," 6   FOOD#PRICES               1708 non-null   int64 \n"," 7   FOOD#QUALITY              1708 non-null   int64 \n"," 8   FOOD#STYLE_OPTIONS        1708 non-null   int64 \n"," 9   LOCATION#GENERAL          1708 non-null   int64 \n"," 10  RESTAURANT#GENERAL        1708 non-null   int64 \n"," 11  RESTAURANT#MISCELLANEOUS  1708 non-null   int64 \n"," 12  RESTAURANT#PRICES         1708 non-null   int64 \n"," 13  SERVICE#GENERAL           1708 non-null   int64 \n","dtypes: int64(13), object(1)\n","memory usage: 186.9+ KB\n"]},{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-272981a5-247e-4fdb-bdcd-0c4fb3dd1bbd\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>comment_text</th>\n","      <th>AMBIENCE#GENERAL</th>\n","      <th>DRINKS#PRICES</th>\n","      <th>DRINKS#QUALITY</th>\n","      <th>DRINKS#STYLE_OPTIONS</th>\n","      <th>FOOD#PRICES</th>\n","      <th>FOOD#QUALITY</th>\n","      <th>FOOD#STYLE_OPTIONS</th>\n","      <th>LOCATION#GENERAL</th>\n","      <th>RESTAURANT#GENERAL</th>\n","      <th>RESTAURANT#MISCELLANEOUS</th>\n","      <th>RESTAURANT#PRICES</th>\n","      <th>SERVICE#GENERAL</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2202</td>\n","      <td>Judging from previous posts this used to be a ...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9326</td>\n","      <td>We, there were four of us, arrived at noon - t...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1034</td>\n","      <td>They never brought us complimentary noodles, i...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4180</td>\n","      <td>The food was lousy - too sweet or too salty an...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1932</td>\n","      <td>After all that, they complained to me about th...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-272981a5-247e-4fdb-bdcd-0c4fb3dd1bbd')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-272981a5-247e-4fdb-bdcd-0c4fb3dd1bbd button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-272981a5-247e-4fdb-bdcd-0c4fb3dd1bbd');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["     id  ... SERVICE#GENERAL\n","0  2202  ...               0\n","1  9326  ...               1\n","2  1034  ...               1\n","3  4180  ...               0\n","4  1932  ...               1\n","\n","[5 rows x 14 columns]"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","metadata":{"id":"6AhWrzX7nITB","colab":{"base_uri":"https://localhost:8080/"},"outputId":"239e9daa-4083-4b4b-febe-529d57ae444e","executionInfo":{"status":"ok","timestamp":1644746944360,"user_tz":-60,"elapsed":7,"user":{"displayName":"Rosa Ryhänen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04493503792992534699"}}},"source":["print('Unique comments: ', df.comment_text.nunique() == df.shape[0])\n","print('Null values: ', df.isnull().values.any())\n","# df[df.isna().any(axis=1)]"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Unique comments:  False\n","Null values:  False\n"]}]},{"cell_type":"code","metadata":{"id":"OkKpz_9eJRt7","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f8e20f6f-a15f-479a-dd0a-1a2685eeb9de","executionInfo":{"status":"ok","timestamp":1644746945414,"user_tz":-60,"elapsed":4,"user":{"displayName":"Rosa Ryhänen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04493503792992534699"}}},"source":["print('average sentence length: ', df.comment_text.str.split().str.len().mean())\n","print('stdev sentence length: ', df.comment_text.str.split().str.len().std())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["average sentence length:  12.507611241217798\n","stdev sentence length:  8.285011666209963\n"]}]},{"cell_type":"code","metadata":{"id":"UVI59S9VaAfB","colab":{"base_uri":"https://localhost:8080/"},"outputId":"14be156a-d2c7-4743-c37a-775a0c264836","executionInfo":{"status":"ok","timestamp":1644746946200,"user_tz":-60,"elapsed":3,"user":{"displayName":"Rosa Ryhänen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04493503792992534699"}}},"source":["cols = df.columns\n","label_cols = list(cols[2:])\n","num_labels = len(label_cols)\n","print('Label columns: ', label_cols)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Label columns:  ['AMBIENCE#GENERAL', 'DRINKS#PRICES', 'DRINKS#QUALITY', 'DRINKS#STYLE_OPTIONS', 'FOOD#PRICES', 'FOOD#QUALITY', 'FOOD#STYLE_OPTIONS', 'LOCATION#GENERAL', 'RESTAURANT#GENERAL', 'RESTAURANT#MISCELLANEOUS', 'RESTAURANT#PRICES', 'SERVICE#GENERAL']\n"]}]},{"cell_type":"code","metadata":{"id":"xzgA5qQgYIBZ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a82177bd-2769-4557-d5e7-f652e36be373","executionInfo":{"status":"ok","timestamp":1644746948964,"user_tz":-60,"elapsed":339,"user":{"displayName":"Rosa Ryhänen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04493503792992534699"}}},"source":["print('Count of 1 per label: \\n', df[label_cols].sum(), '\\n') # Label counts, may need to downsample or upsample\n","print('Count of 0 per label: \\n', df[label_cols].eq(0).sum())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Count of 1 per label: \n"," AMBIENCE#GENERAL            226\n","DRINKS#PRICES                20\n","DRINKS#QUALITY               46\n","DRINKS#STYLE_OPTIONS         30\n","FOOD#PRICES                  82\n","FOOD#QUALITY                681\n","FOOD#STYLE_OPTIONS          128\n","LOCATION#GENERAL             28\n","RESTAURANT#GENERAL          421\n","RESTAURANT#MISCELLANEOUS     97\n","RESTAURANT#PRICES            80\n","SERVICE#GENERAL             419\n","dtype: int64 \n","\n","Count of 0 per label: \n"," AMBIENCE#GENERAL            1482\n","DRINKS#PRICES               1688\n","DRINKS#QUALITY              1662\n","DRINKS#STYLE_OPTIONS        1678\n","FOOD#PRICES                 1626\n","FOOD#QUALITY                1027\n","FOOD#STYLE_OPTIONS          1580\n","LOCATION#GENERAL            1680\n","RESTAURANT#GENERAL          1287\n","RESTAURANT#MISCELLANEOUS    1611\n","RESTAURANT#PRICES           1628\n","SERVICE#GENERAL             1289\n","dtype: int64\n"]}]},{"cell_type":"code","metadata":{"id":"uFpSd4JzaAae"},"source":["df = df.sample(frac=1).reset_index(drop=True) #shuffle rows"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0DF3ddjej5vd","colab":{"base_uri":"https://localhost:8080/","height":496},"outputId":"6d6c7ab9-c4c8-45cf-f1b6-6b2de5334a80","executionInfo":{"status":"ok","timestamp":1644746952339,"user_tz":-60,"elapsed":9,"user":{"displayName":"Rosa Ryhänen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04493503792992534699"}}},"source":["df['one_hot_labels'] = list(df[label_cols].values)\n","df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-0b875dff-afd9-49e2-bead-7adfde11dc2f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>comment_text</th>\n","      <th>AMBIENCE#GENERAL</th>\n","      <th>DRINKS#PRICES</th>\n","      <th>DRINKS#QUALITY</th>\n","      <th>DRINKS#STYLE_OPTIONS</th>\n","      <th>FOOD#PRICES</th>\n","      <th>FOOD#QUALITY</th>\n","      <th>FOOD#STYLE_OPTIONS</th>\n","      <th>LOCATION#GENERAL</th>\n","      <th>RESTAURANT#GENERAL</th>\n","      <th>RESTAURANT#MISCELLANEOUS</th>\n","      <th>RESTAURANT#PRICES</th>\n","      <th>SERVICE#GENERAL</th>\n","      <th>one_hot_labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2285</td>\n","      <td>I've enjoyed 99% of the dishes we've ordered w...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9845</td>\n","      <td>I found the food to be outstanding, particular...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9502</td>\n","      <td>Be sure not to get anything other than bagels!..</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>6334</td>\n","      <td>Tiny dessert was $8.00...just plain overpriced...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6898</td>\n","      <td>MMmmm... it was delicious.</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0b875dff-afd9-49e2-bead-7adfde11dc2f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0b875dff-afd9-49e2-bead-7adfde11dc2f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0b875dff-afd9-49e2-bead-7adfde11dc2f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["     id  ...                        one_hot_labels\n","0  2285  ...  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n","1  9845  ...  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n","2  9502  ...  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n","3  6334  ...  [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0]\n","4  6898  ...  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n","\n","[5 rows x 15 columns]"]},"metadata":{},"execution_count":52}]},{"cell_type":"code","metadata":{"id":"MlhHifh5bW7e"},"source":["labels = list(df.one_hot_labels.values)\n","comments = list(df.comment_text.values)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IlMHfElhGJzc"},"source":["Load the pretrained tokenizer that corresponds to your choice in model. e.g.,\n","\n","```\n","BERT:\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True) \n","\n","XLNet:\n","tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=False) \n","\n","RoBERTa:\n","tokenizer = RobertaTokenizer.from_pretrained('roberta-base', do_lower_case=False)\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"IhVr8SziL_PY"},"source":["In order to avoid memory issues with Google Colab, I enforce a max_length of 100 tokens. Note that some sentences may not adequately represent each label because of this."]},{"cell_type":"code","metadata":{"id":"HNsEu-vUur-4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"80730efa-a0e7-42f7-9617-be4bbbba2843","executionInfo":{"status":"ok","timestamp":1644746956395,"user_tz":-60,"elapsed":937,"user":{"displayName":"Rosa Ryhänen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04493503792992534699"}}},"source":["from transformers import BertTokenizer\n","max_length = 100\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True) # tokenizer\n","encodings = tokenizer.batch_encode_plus(comments,max_length=max_length,pad_to_max_length=True) # tokenizer's encoding method\n","print('tokenizer outputs: ', encodings.keys())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"stream","name":"stdout","text":["tokenizer outputs:  dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n"]}]},{"cell_type":"code","metadata":{"id":"l6CCLSjfur-9"},"source":["input_ids = encodings['input_ids'] # tokenized and encoded sentences\n","token_type_ids = encodings['token_type_ids'] # token type ids\n","attention_masks = encodings['attention_mask'] # attention masks"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vSOFbThlYcpb","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6866d5d5-7689-493f-e034-1131cb5bcc1c","executionInfo":{"status":"ok","timestamp":1644746960327,"user_tz":-60,"elapsed":9,"user":{"displayName":"Rosa Ryhänen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04493503792992534699"}}},"source":["# Identifying indices of 'one_hot_labels' entries that only occur once - this will allow us to stratify split our training data later\n","label_counts = df.one_hot_labels.astype(str).value_counts()\n","one_freq = label_counts[label_counts==1].keys()\n","one_freq_idxs = sorted(list(df[df.one_hot_labels.astype(str).isin(one_freq)].index), reverse=True)\n","print('df label indices with only one instance: ', one_freq_idxs)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["df label indices with only one instance:  [1686, 1633, 1602, 1527, 1499, 1469, 1457, 1416, 1343, 1320, 1289, 1250, 1224, 1204, 1199, 1189, 1174, 1163, 1090, 930, 909, 864, 857, 848, 835, 823, 791, 724, 720, 618, 554, 536, 430, 421, 416, 408, 400, 325, 316, 236, 187, 153, 121, 40, 24]\n"]}]},{"cell_type":"code","metadata":{"id":"CQQ7CoOag_r7"},"source":["# Gathering single instance inputs to force into the training set after stratified split\n","one_freq_input_ids = [input_ids.pop(i) for i in one_freq_idxs]\n","one_freq_token_types = [token_type_ids.pop(i) for i in one_freq_idxs]\n","one_freq_attention_masks = [attention_masks.pop(i) for i in one_freq_idxs]\n","one_freq_labels = [labels.pop(i) for i in one_freq_idxs]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r9PxAt48HRRj"},"source":["Be sure to handle all classes during validation using \"stratify\" during train/validation split:"]},{"cell_type":"code","metadata":{"id":"WPFaq4ufnIT2"},"source":["# Use train_test_split to split our data into train and validation sets\n","\n","train_inputs, validation_inputs, train_labels, validation_labels, train_token_types, validation_token_types, train_masks, validation_masks = train_test_split(input_ids, labels, token_type_ids,attention_masks,\n","                                                            random_state=2020, test_size=0.10, stratify = labels)\n","\n","# Add one frequency data to train data\n","train_inputs.extend(one_freq_input_ids)\n","train_labels.extend(one_freq_labels)\n","train_masks.extend(one_freq_attention_masks)\n","train_token_types.extend(one_freq_token_types)\n","\n","# Convert all of our data into torch tensors, the required datatype for our model\n","train_inputs = torch.tensor(train_inputs)\n","train_labels = torch.tensor(train_labels)\n","train_masks = torch.tensor(train_masks)\n","train_token_types = torch.tensor(train_token_types)\n","\n","validation_inputs = torch.tensor(validation_inputs)\n","validation_labels = torch.tensor(validation_labels)\n","validation_masks = torch.tensor(validation_masks)\n","validation_token_types = torch.tensor(validation_token_types)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZRnuLna-nIT4"},"source":["# Select a batch size for training. For fine-tuning with XLNet, the authors recommend a batch size of 32, 48, or 128. We will use 32 here to avoid memory issues.\n","batch_size = 32\n","\n","# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n","# with an iterator the entire dataset does not need to be loaded into memory\n","\n","train_data = TensorDataset(train_inputs, train_masks, train_labels, train_token_types)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels, validation_token_types)\n","validation_sampler = SequentialSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iiFRnP_ZTBFa"},"source":["torch.save(validation_dataloader,'validation_data_loader')\n","torch.save(train_dataloader,'train_data_loader')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ncGteBuSFuZM"},"source":["## Load Model & Set Params"]},{"cell_type":"markdown","metadata":{"id":"Z0dL-Bz_NrGj"},"source":["Load the appropriate model below, each model already contains a single dense layer for classification on top.\n","\n","\n","\n","```\n","BERT:\n","model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)\n","\n","XLNet:\n","model = XLNetForSequenceClassification.from_pretrained(\"xlnet-base-cased\", num_labels=num_labels)\n","\n","RoBERTa:\n","model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=num_labels)\n","```\n","\n"]},{"cell_type":"code","metadata":{"id":"Ujk4k16DnIT6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644746970762,"user_tz":-60,"elapsed":1709,"user":{"displayName":"Rosa Ryhänen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04493503792992534699"}},"outputId":"1330bcc7-a838-4ea3-ba2d-1022209adf5f"},"source":["# Load model, the pretrained model will include a single linear classification layer on top for classification. \n","from transformers import BertForSequenceClassification\n","\n","model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)\n","model.cuda()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=12, bias=True)\n",")"]},"metadata":{},"execution_count":62}]},{"cell_type":"markdown","metadata":{"id":"jGE4gv9qfhRG"},"source":["Setting custom optimization parameters for the AdamW optimizer https://huggingface.co/transformers/main_classes/optimizer_schedules.html"]},{"cell_type":"code","metadata":{"id":"GsV8zwWYnIT9"},"source":["# setting custom optimization parameters. You may implement a scheduler here as well.\n","param_optimizer = list(model.named_parameters())\n","no_decay = ['bias', 'gamma', 'beta']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.01},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.0}\n","]"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install tensorflow_addons"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4sOyXXDCnxR4","executionInfo":{"status":"ok","timestamp":1644746149635,"user_tz":-60,"elapsed":3398,"user":{"displayName":"Rosa Ryhänen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04493503792992534699"}},"outputId":"e63d50cf-2803-4562-e82a-f48654316aaa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow_addons\n","  Downloading tensorflow_addons-0.15.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[?25l\r\u001b[K     |▎                               | 10 kB 21.8 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 35.5 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 39.4 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51 kB 35.0 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61 kB 38.0 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92 kB 29.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 102 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████                           | 174 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████                         | 245 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 256 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████                        | 276 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 286 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 307 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 337 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 358 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 368 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 389 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 399 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 430 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 440 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 460 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 471 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 481 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 501 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 512 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 522 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 532 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 542 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 552 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 563 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 573 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 583 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 604 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 614 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 624 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 634 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 645 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 655 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 675 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 686 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 696 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 706 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 716 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 727 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 737 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 747 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 757 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 768 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 778 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 788 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 798 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 808 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 819 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 829 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 849 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 860 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 870 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 880 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 890 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 901 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 911 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 921 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 931 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 942 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 952 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 962 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 972 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 983 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 993 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0 MB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0 MB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.0 MB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0 MB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0 MB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1 MB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1 MB 29.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.1 MB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1 MB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.1 MB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.1 MB 29.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 29.4 MB/s \n","\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n","Installing collected packages: tensorflow-addons\n","Successfully installed tensorflow-addons-0.15.0\n"]}]},{"cell_type":"code","metadata":{"id":"aOomZIEIoHOL"},"source":["import tensorflow as tf\n","import tensorflow_addons as tfa\n","\n","optimizer = torch.optim.AdamW(optimizer_grouped_parameters,lr=2e-5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JRQQZ8zIFzLW"},"source":["## Train Model"]},{"cell_type":"code","metadata":{"id":"uDLZmEC_oKo3","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b26d5be6-c334-4620-f4e9-fa8fe4d10737","executionInfo":{"status":"ok","timestamp":1644747464491,"user_tz":-60,"elapsed":264341,"user":{"displayName":"Rosa Ryhänen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04493503792992534699"}}},"source":["# Store our loss and accuracy for plotting\n","train_loss_set = []\n","\n","# Number of training epochs (authors recommend between 2 and 4)\n","epochs = 10\n","\n","# trange is a tqdm wrapper around the normal python range\n","for _ in trange(epochs, desc=\"Epoch\"):\n","\n","  # Training\n","  \n","  # Set our model to training mode (as opposed to evaluation mode)\n","  model.train()\n","\n","  # Tracking variables\n","  tr_loss = 0 #running loss\n","  nb_tr_examples, nb_tr_steps = 0, 0\n","  \n","  # Train the data for one epoch\n","  for step, batch in enumerate(train_dataloader):\n","    # Add batch to GPU\n","    batch = tuple(t.to(device) for t in batch)\n","    # Unpack the inputs from our dataloader\n","    b_input_ids, b_input_mask, b_labels, b_token_types = batch\n","    # Clear out the gradients (by default they accumulate)\n","    optimizer.zero_grad()\n","\n","    # # Forward pass for multiclass classification\n","    # outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n","    # loss = outputs[0]\n","    # logits = outputs[1]\n","\n","    # Forward pass for multilabel classification\n","    outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","    logits = outputs[0]\n","    loss_func = BCEWithLogitsLoss() \n","    loss = loss_func(logits.view(-1,num_labels),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n","    # loss_func = BCELoss() \n","    # loss = loss_func(torch.sigmoid(logits.view(-1,num_labels)),b_labels.type_as(logits).view(-1,num_labels)) #convert labels to float for calculation\n","    train_loss_set.append(loss.item())    \n","\n","    # Backward pass\n","    loss.backward()\n","    # Update parameters and take a step using the computed gradient\n","    optimizer.step()\n","    # scheduler.step()\n","    # Update tracking variables\n","    tr_loss += loss.item()\n","    nb_tr_examples += b_input_ids.size(0)\n","    nb_tr_steps += 1\n","\n","  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n","\n","###############################################################################\n","\n","  # Validation\n","\n","  # Put model in evaluation mode to evaluate loss on the validation set\n","  model.eval()\n","\n","  # Variables to gather full output\n","  logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n","\n","  # Predict\n","  for i, batch in enumerate(validation_dataloader):\n","    batch = tuple(t.to(device) for t in batch)\n","    # Unpack the inputs from our dataloader\n","    b_input_ids, b_input_mask, b_labels, b_token_types = batch\n","    with torch.no_grad():\n","      # Forward pass\n","      outs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","      b_logit_pred = outs[0]\n","      pred_label = torch.sigmoid(b_logit_pred)\n","\n","      b_logit_pred = b_logit_pred.detach().cpu().numpy()\n","      pred_label = pred_label.to('cpu').numpy()\n","      b_labels = b_labels.to('cpu').numpy()\n","\n","    tokenized_texts.append(b_input_ids)\n","    logit_preds.append(b_logit_pred)\n","    true_labels.append(b_labels)\n","    pred_labels.append(pred_label)\n","\n","  # Flatten outputs\n","  pred_labels = [item for sublist in pred_labels for item in sublist]\n","  true_labels = [item for sublist in true_labels for item in sublist]\n","\n","  # Calculate Accuracy\n","  threshold = 0.50\n","  pred_bools = [pl>threshold for pl in pred_labels]\n","  true_bools = [tl==1 for tl in true_labels]\n","  val_f1_accuracy = f1_score(true_bools,pred_bools,average='micro')*100\n","  val_flat_accuracy = accuracy_score(true_bools, pred_bools)*100\n","\n","  print('F1 Validation Accuracy: ', val_f1_accuracy)\n","  print('Flat Validation Accuracy: ', val_flat_accuracy)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\rEpoch:   0%|          | 0/10 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Train loss: 0.1488761860801249\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  10%|█         | 1/10 [00:25<03:48, 25.42s/it]"]},{"output_type":"stream","name":"stdout","text":["F1 Validation Accuracy:  75.63025210084034\n","Flat Validation Accuracy:  58.68263473053892\n","Train loss: 0.1283767500094005\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  20%|██        | 2/10 [00:51<03:26, 25.79s/it]"]},{"output_type":"stream","name":"stdout","text":["F1 Validation Accuracy:  76.03305785123968\n","Flat Validation Accuracy:  62.27544910179641\n","Train loss: 0.11080042706156264\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  30%|███       | 3/10 [01:18<03:04, 26.31s/it]"]},{"output_type":"stream","name":"stdout","text":["F1 Validation Accuracy:  76.50273224043715\n","Flat Validation Accuracy:  62.27544910179641\n","Train loss: 0.09773578160271353\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  40%|████      | 4/10 [01:44<02:38, 26.40s/it]"]},{"output_type":"stream","name":"stdout","text":["F1 Validation Accuracy:  79.13279132791328\n","Flat Validation Accuracy:  64.67065868263472\n","Train loss: 0.08667493018568778\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  50%|█████     | 5/10 [02:11<02:11, 26.40s/it]"]},{"output_type":"stream","name":"stdout","text":["F1 Validation Accuracy:  79.25531914893618\n","Flat Validation Accuracy:  64.67065868263472\n","Train loss: 0.07630781760933447\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  60%|██████    | 6/10 [02:37<01:45, 26.42s/it]"]},{"output_type":"stream","name":"stdout","text":["F1 Validation Accuracy:  79.58115183246073\n","Flat Validation Accuracy:  67.06586826347305\n","Train loss: 0.06975309178233147\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  70%|███████   | 7/10 [03:04<01:19, 26.48s/it]"]},{"output_type":"stream","name":"stdout","text":["F1 Validation Accuracy:  80.0\n","Flat Validation Accuracy:  66.46706586826348\n","Train loss: 0.06255444260884305\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  80%|████████  | 8/10 [03:30<00:52, 26.50s/it]"]},{"output_type":"stream","name":"stdout","text":["F1 Validation Accuracy:  80.72916666666667\n","Flat Validation Accuracy:  68.26347305389223\n","Train loss: 0.05527514226886691\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  90%|█████████ | 9/10 [03:57<00:26, 26.49s/it]"]},{"output_type":"stream","name":"stdout","text":["F1 Validation Accuracy:  79.8941798941799\n","Flat Validation Accuracy:  67.66467065868264\n","Train loss: 0.04951700267895144\n"]},{"output_type":"stream","name":"stderr","text":["Epoch: 100%|██████████| 10/10 [04:23<00:00, 26.39s/it]"]},{"output_type":"stream","name":"stdout","text":["F1 Validation Accuracy:  79.36507936507937\n","Flat Validation Accuracy:  66.46706586826348\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","metadata":{"id":"aiBeiBSRoOuz"},"source":["torch.save(model.state_dict(), 'bert_model_original_10')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_7dd2GE3F4yK"},"source":["## Load and Preprocess Test Data"]},{"cell_type":"code","source":["test_set = \"/content/drive/My Drive/TFM_Rosa-Maria/multilabel-classification/original-data/test.csv\""],"metadata":{"id":"C_BOfaL0zwXa"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G5Q7hC4GFOLJ","colab":{"base_uri":"https://localhost:8080/","height":392},"outputId":"be21bcbb-73cd-4be4-eaa3-9e5cf9ba0d40","executionInfo":{"status":"ok","timestamp":1644747470089,"user_tz":-60,"elapsed":313,"user":{"displayName":"Rosa Ryhänen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04493503792992534699"}}},"source":["test_df = pd.read_csv(test_set)\n","test_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-1ef82b88-e268-45dc-aee2-7bccfd4a6919\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>comment_text</th>\n","      <th>AMBIENCE#GENERAL</th>\n","      <th>DRINKS#PRICES</th>\n","      <th>DRINKS#QUALITY</th>\n","      <th>DRINKS#STYLE_OPTIONS</th>\n","      <th>FOOD#PRICES</th>\n","      <th>FOOD#QUALITY</th>\n","      <th>FOOD#STYLE_OPTIONS</th>\n","      <th>LOCATION#GENERAL</th>\n","      <th>RESTAURANT#GENERAL</th>\n","      <th>RESTAURANT#MISCELLANEOUS</th>\n","      <th>RESTAURANT#PRICES</th>\n","      <th>SERVICE#GENERAL</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>12201</td>\n","      <td>Yum!</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>19325</td>\n","      <td>Serves really good sushi.</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>11033</td>\n","      <td>Not the biggest portions but adequate.</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>14179</td>\n","      <td>Green Tea creme brulee is a must!</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>11931</td>\n","      <td>Don't leave the restaurant without it.</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ef82b88-e268-45dc-aee2-7bccfd4a6919')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1ef82b88-e268-45dc-aee2-7bccfd4a6919 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1ef82b88-e268-45dc-aee2-7bccfd4a6919');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["      id  ... SERVICE#GENERAL\n","0  12201  ...               0\n","1  19325  ...               0\n","2  11033  ...               0\n","3  14179  ...               0\n","4  11931  ...               0\n","\n","[5 rows x 14 columns]"]},"metadata":{},"execution_count":77}]},{"cell_type":"code","metadata":{"id":"77rjCrMGpYxz","colab":{"base_uri":"https://localhost:8080/","height":409},"outputId":"c6e2ddc9-fce8-4129-9c6a-7fd46d26194f","executionInfo":{"status":"ok","timestamp":1644747472130,"user_tz":-60,"elapsed":10,"user":{"displayName":"Rosa Ryhänen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04493503792992534699"}}},"source":["cols_test = test_df.columns\n","label_cols_test = list(cols_test[2:])\n","num_labels_test = len(label_cols_test)\n","test_df['one_hot_labels'] = list(test_df[label_cols_test].values)\n","test_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-d4e3d719-c376-4d3f-b015-57d2f90e7919\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>comment_text</th>\n","      <th>AMBIENCE#GENERAL</th>\n","      <th>DRINKS#PRICES</th>\n","      <th>DRINKS#QUALITY</th>\n","      <th>DRINKS#STYLE_OPTIONS</th>\n","      <th>FOOD#PRICES</th>\n","      <th>FOOD#QUALITY</th>\n","      <th>FOOD#STYLE_OPTIONS</th>\n","      <th>LOCATION#GENERAL</th>\n","      <th>RESTAURANT#GENERAL</th>\n","      <th>RESTAURANT#MISCELLANEOUS</th>\n","      <th>RESTAURANT#PRICES</th>\n","      <th>SERVICE#GENERAL</th>\n","      <th>one_hot_labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>12201</td>\n","      <td>Yum!</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>19325</td>\n","      <td>Serves really good sushi.</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>11033</td>\n","      <td>Not the biggest portions but adequate.</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>14179</td>\n","      <td>Green Tea creme brulee is a must!</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>11931</td>\n","      <td>Don't leave the restaurant without it.</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d4e3d719-c376-4d3f-b015-57d2f90e7919')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d4e3d719-c376-4d3f-b015-57d2f90e7919 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d4e3d719-c376-4d3f-b015-57d2f90e7919');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["      id  ...                        one_hot_labels\n","0  12201  ...  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n","1  19325  ...  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n","2  11033  ...  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n","3  14179  ...  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n","4  11931  ...  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n","\n","[5 rows x 15 columns]"]},"metadata":{},"execution_count":78}]},{"cell_type":"code","metadata":{"id":"1a41OmU2i7qp"},"source":["# Gathering input data\n","test_labels = list(test_df.one_hot_labels.values)\n","test_comments = list(test_df.comment_text.values)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"amySMO8EQzf2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644747476229,"user_tz":-60,"elapsed":6,"user":{"displayName":"Rosa Ryhänen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04493503792992534699"}},"outputId":"04a22176-7045-4ef2-ef18-8b0cdce11a7e"},"source":["# Encoding input data\n","test_encodings = tokenizer.batch_encode_plus(test_comments,max_length=max_length,pad_to_max_length=True)\n","test_input_ids = test_encodings['input_ids']\n","test_token_type_ids = test_encodings['token_type_ids']\n","test_attention_masks = test_encodings['attention_mask']"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2257: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]}]},{"cell_type":"code","metadata":{"id":"hqOfi9fkRaRN"},"source":["# Make tensors out of data\n","test_inputs = torch.tensor(test_input_ids)\n","test_labels = torch.tensor(test_labels)\n","test_masks = torch.tensor(test_attention_masks)\n","test_token_types = torch.tensor(test_token_type_ids)\n","# Create test dataloader\n","test_data = TensorDataset(test_inputs, test_masks, test_labels, test_token_types)\n","test_sampler = SequentialSampler(test_data)\n","test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n","# Save test dataloader\n","torch.save(test_dataloader,'test_data_loader')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PFTWxCA_GBau"},"source":["## Prediction and Metics"]},{"cell_type":"code","metadata":{"id":"NPvrL6OFSQvf"},"source":["# Test\n","\n","# Put model in evaluation mode to evaluate loss on the validation set\n","model.eval()\n","\n","#track variables\n","logit_preds,true_labels,pred_labels,tokenized_texts = [],[],[],[]\n","\n","# Predict\n","for i, batch in enumerate(test_dataloader):\n","  batch = tuple(t.to(device) for t in batch)\n","  # Unpack the inputs from our dataloader\n","  b_input_ids, b_input_mask, b_labels, b_token_types = batch\n","  with torch.no_grad():\n","    # Forward pass\n","    outs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","    b_logit_pred = outs[0]\n","    pred_label = torch.sigmoid(b_logit_pred)\n","\n","    b_logit_pred = b_logit_pred.detach().cpu().numpy()\n","    pred_label = pred_label.to('cpu').numpy()\n","    b_labels = b_labels.to('cpu').numpy()\n","\n","  tokenized_texts.append(b_input_ids)\n","  logit_preds.append(b_logit_pred)\n","  true_labels.append(b_labels)\n","  pred_labels.append(pred_label)\n","\n","# Flatten outputs\n","tokenized_texts = [item for sublist in tokenized_texts for item in sublist]\n","pred_labels = [item for sublist in pred_labels for item in sublist]\n","true_labels = [item for sublist in true_labels for item in sublist]\n","# Converting flattened binary values to boolean values\n","true_bools = [tl==1 for tl in true_labels]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bQeGWqeMzAoZ"},"source":["We need to threshold our sigmoid function outputs which range from [0, 1]. Below I use 0.50 as a threshold."]},{"cell_type":"code","metadata":{"id":"BZcZUcYOxxmM","colab":{"base_uri":"https://localhost:8080/"},"outputId":"624b73c9-dd56-4aad-ddc0-8c4632ded061","executionInfo":{"status":"ok","timestamp":1644747484548,"user_tz":-60,"elapsed":340,"user":{"displayName":"Rosa Ryhänen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04493503792992534699"}}},"source":["pred_bools = [pl>0.50 for pl in pred_labels] #boolean output after thresholding\n","\n","# Print and save classification report\n","print('Test F1 Accuracy: ', f1_score(true_bools, pred_bools,average='micro'))\n","print('Test Flat Accuracy: ', accuracy_score(true_bools, pred_bools),'\\n')\n","clf_report = classification_report(true_bools,pred_bools,target_names=label_cols_test)\n","pickle.dump(clf_report, open('classification_report_original_10.txt','wb')) #save report\n","print(clf_report)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test F1 Accuracy:  0.7789776817854572\n","Test Flat Accuracy:  0.65587734241908 \n","\n","                          precision    recall  f1-score   support\n","\n","        AMBIENCE#GENERAL       0.80      0.89      0.84        57\n","           DRINKS#PRICES       0.00      0.00      0.00         3\n","          DRINKS#QUALITY       0.62      0.38      0.47        21\n","    DRINKS#STYLE_OPTIONS       0.50      0.25      0.33        12\n","             FOOD#PRICES       0.67      0.64      0.65        22\n","            FOOD#QUALITY       0.87      0.90      0.88       226\n","      FOOD#STYLE_OPTIONS       0.62      0.44      0.51        48\n","        LOCATION#GENERAL       1.00      0.08      0.14        13\n","      RESTAURANT#GENERAL       0.88      0.69      0.77       142\n","RESTAURANT#MISCELLANEOUS       0.42      0.15      0.22        33\n","       RESTAURANT#PRICES       0.78      0.33      0.47        21\n","         SERVICE#GENERAL       0.92      0.90      0.91       145\n","\n","               micro avg       0.84      0.73      0.78       743\n","               macro avg       0.67      0.47      0.52       743\n","            weighted avg       0.82      0.73      0.76       743\n","             samples avg       0.79      0.75      0.76       743\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"markdown","metadata":{"id":"5rLqrHK87eir"},"source":["## Output Dataframe"]},{"cell_type":"code","metadata":{"id":"CJBkRdGN1hzx","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f9e771ac-bf14-4056-96dd-8b51bb8fca27","executionInfo":{"status":"ok","timestamp":1644175679281,"user_tz":-60,"elapsed":307,"user":{"displayName":"Rosa Ryhänen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04493503792992534699"}}},"source":["idx2label = dict(zip(range(12),label_cols))\n","print(idx2label)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{0: 'AMBIENCE#GENERAL', 1: 'DRINKS#PRICES', 2: 'DRINKS#QUALITY', 3: 'DRINKS#STYLE_OPTIONS', 4: 'FOOD#PRICES', 5: 'FOOD#QUALITY', 6: 'FOOD#STYLE_OPTIONS', 7: 'LOCATION#GENERAL', 8: 'RESTAURANT#GENERAL', 9: 'RESTAURANT#MISCELLANEOUS', 10: 'RESTAURANT#PRICES', 11: 'SERVICE#GENERAL'}\n"]}]},{"cell_type":"code","metadata":{"id":"QZUglV_A4BF_"},"source":["# Getting indices of where boolean one hot vector true_bools is True so we can use idx2label to gather label names\n","true_label_idxs, pred_label_idxs=[],[]\n","for vals in true_bools:\n","  true_label_idxs.append(np.where(vals)[0].flatten().tolist())\n","for vals in pred_bools:\n","  pred_label_idxs.append(np.where(vals)[0].flatten().tolist())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OOGhXM3R4a91"},"source":["# Gathering vectors of label names using idx2label\n","true_label_texts, pred_label_texts = [], []\n","for vals in true_label_idxs:\n","  if vals:\n","    true_label_texts.append([idx2label[val] for val in vals])\n","  else:\n","    true_label_texts.append(vals)\n","\n","for vals in pred_label_idxs:\n","  if vals:\n","    pred_label_texts.append([idx2label[val] for val in vals])\n","  else:\n","    pred_label_texts.append(vals)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5HaqV6pn_HCG"},"source":["# Decoding input ids to comment text\n","comment_texts = [tokenizer.decode(text,skip_special_tokens=True,clean_up_tokenization_spaces=False) for text in tokenized_texts]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R7kk0Mgl1L-T","colab":{"base_uri":"https://localhost:8080/","height":206},"outputId":"0afdb43f-5c4e-41dc-a60b-780638e73d88","executionInfo":{"status":"ok","timestamp":1644175687986,"user_tz":-60,"elapsed":314,"user":{"displayName":"Rosa Ryhänen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04493503792992534699"}}},"source":["# Converting lists to df\n","comparisons_df = pd.DataFrame({'comment_text': comment_texts, 'true_labels': true_label_texts, 'pred_labels':pred_label_texts})\n","comparisons_df.to_csv('comparisons_gold_10.csv')\n","comparisons_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-b034c89e-f1d7-439f-82f7-5b46d169e820\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>comment_text</th>\n","      <th>true_labels</th>\n","      <th>pred_labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>yum !</td>\n","      <td>[FOOD#QUALITY]</td>\n","      <td>[FOOD#QUALITY]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>serves really good sushi .</td>\n","      <td>[FOOD#QUALITY]</td>\n","      <td>[FOOD#QUALITY]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>not the biggest portions but adequate .</td>\n","      <td>[FOOD#STYLE_OPTIONS]</td>\n","      <td>[FOOD#STYLE_OPTIONS]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>green tea creme brulee is a must !</td>\n","      <td>[FOOD#QUALITY]</td>\n","      <td>[FOOD#QUALITY]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>don ' t leave the restaurant without green tea...</td>\n","      <td>[FOOD#QUALITY]</td>\n","      <td>[FOOD#QUALITY]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b034c89e-f1d7-439f-82f7-5b46d169e820')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b034c89e-f1d7-439f-82f7-5b46d169e820 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b034c89e-f1d7-439f-82f7-5b46d169e820');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                        comment_text  ...           pred_labels\n","0                                              yum !  ...        [FOOD#QUALITY]\n","1                         serves really good sushi .  ...        [FOOD#QUALITY]\n","2            not the biggest portions but adequate .  ...  [FOOD#STYLE_OPTIONS]\n","3                 green tea creme brulee is a must !  ...        [FOOD#QUALITY]\n","4  don ' t leave the restaurant without green tea...  ...        [FOOD#QUALITY]\n","\n","[5 rows x 3 columns]"]},"metadata":{},"execution_count":174}]},{"cell_type":"markdown","metadata":{"id":"PWFd18u3zlF8"},"source":["## Bonus - Optimizing threshold value for micro F1 score"]},{"cell_type":"markdown","metadata":{"id":"c6mDy1lw0S4y"},"source":["Doing this may result in a trade offs between precision, flat accuracy and micro F1 accuracy. You may tune the threshold however you want."]},{"cell_type":"code","metadata":{"id":"PHlhb2lvar8V","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e375e595-d312-484e-8cb7-3469e01aaf94","executionInfo":{"status":"ok","timestamp":1644176312273,"user_tz":-60,"elapsed":662,"user":{"displayName":"Rosa Ryhänen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04493503792992534699"}}},"source":["# Calculate Accuracy - maximize F1 accuracy by tuning threshold values. First with 'macro_thresholds' on the order of e^-1 then with 'micro_thresholds' on the order of e^-2\n","\n","macro_thresholds = np.array(range(1,10))/10\n","\n","f1_results, flat_acc_results = [], []\n","for th in macro_thresholds:\n","  pred_bools = [pl>th for pl in pred_labels]\n","  test_f1_accuracy = f1_score(true_bools,pred_bools,average='micro')\n","  test_flat_accuracy = accuracy_score(true_bools, pred_bools)\n","  f1_results.append(test_f1_accuracy)\n","  flat_acc_results.append(test_flat_accuracy)\n","\n","best_macro_th = macro_thresholds[np.argmax(f1_results)] #best macro threshold value\n","\n","micro_thresholds = (np.array(range(10))/100)+best_macro_th #calculating micro threshold values\n","\n","f1_results, flat_acc_results = [], []\n","for th in micro_thresholds:\n","  pred_bools = [pl>th for pl in pred_labels]\n","  test_f1_accuracy = f1_score(true_bools,pred_bools,average='micro')\n","  test_flat_accuracy = accuracy_score(true_bools, pred_bools)\n","  f1_results.append(test_f1_accuracy)\n","  flat_acc_results.append(test_flat_accuracy)\n","\n","best_f1_idx = np.argmax(f1_results) #best threshold value\n","\n","# Printing and saving classification report\n","print('Best Threshold: ', micro_thresholds[best_f1_idx])\n","print('Test F1 Accuracy: ', f1_results[best_f1_idx])\n","print('Test Flat Accuracy: ', flat_acc_results[best_f1_idx], '\\n')\n","\n","best_pred_bools = [pl>micro_thresholds[best_f1_idx] for pl in pred_labels]\n","clf_report_optimized = classification_report(true_bools,best_pred_bools, target_names=label_cols)\n","pickle.dump(clf_report_optimized, open('classification_report_optimized_gold_5.txt','wb'))\n","print(clf_report_optimized)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Threshold:  0.51\n","Test F1 Accuracy:  0.8136518771331057\n","Test Flat Accuracy:  0.6933560477001703 \n","\n","                          precision    recall  f1-score   support\n","\n","        AMBIENCE#GENERAL       0.77      0.93      0.84        57\n","           DRINKS#PRICES       0.50      0.33      0.40         3\n","          DRINKS#QUALITY       0.83      0.71      0.77        21\n","    DRINKS#STYLE_OPTIONS       1.00      0.67      0.80        12\n","             FOOD#PRICES       0.73      0.73      0.73        22\n","            FOOD#QUALITY       0.87      0.96      0.92       226\n","      FOOD#STYLE_OPTIONS       0.66      0.60      0.63        48\n","        LOCATION#GENERAL       1.00      0.54      0.70        13\n","      RESTAURANT#GENERAL       0.83      0.67      0.74       142\n","RESTAURANT#MISCELLANEOUS       0.43      0.27      0.33        33\n","       RESTAURANT#PRICES       0.72      0.62      0.67        21\n","         SERVICE#GENERAL       0.89      0.91      0.90       145\n","\n","               micro avg       0.83      0.80      0.81       743\n","               macro avg       0.77      0.66      0.70       743\n","            weighted avg       0.82      0.80      0.80       743\n","             samples avg       0.81      0.81      0.80       743\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]}]}