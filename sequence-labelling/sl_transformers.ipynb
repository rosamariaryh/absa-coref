{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zy4oz68tC-Tn"
      },
      "source": [
        "# Sequence labelling with transformers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up transformers and drive"
      ],
      "metadata": {
        "id": "Cyubs831mHL7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IK2LQyJE623",
        "outputId": "48943c6a-1d64-49cd-d376-dbd2b701f65d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YdnKXswBJbx",
        "outputId": "3883996a-162a-46ee-dfd0-8af8da66a85d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==2.7.0\n",
            "  Downloading transformers-2.7.0-py3-none-any.whl (544 kB)\n",
            "\u001b[K     |████████████████████████████████| 544 kB 5.5 MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "  Downloading boto3-1.21.42-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 40.3 MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 36.0 MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.5.2\n",
            "  Downloading tokenizers-0.5.2-cp37-cp37m-manylinux1_x86_64.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 20.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.7.0) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.7.0) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.7.0) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.7.0) (1.21.5)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 39.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.7.0) (3.6.0)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 6.5 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n",
            "Collecting botocore<1.25.0,>=1.24.42\n",
            "  Downloading botocore-1.24.42-py3-none-any.whl (8.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.7 MB 34.8 MB/s \n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 45.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.25.0,>=1.24.42->boto3->transformers==2.7.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.42->boto3->transformers==2.7.0) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.7.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.7.0) (2021.10.8)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 42.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.7.0) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.7.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.7.0) (1.1.0)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, tokenizers, sentencepiece, sacremoses, boto3, transformers\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.21.42 botocore-1.24.42 jmespath-1.0.0 s3transfer-0.5.2 sacremoses-0.0.49 sentencepiece-0.1.96 tokenizers-0.5.2 transformers-2.7.0 urllib3-1.25.11\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 840 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.21.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=5b96fc633ca1a29f056d794a10e2e53d01211ed2c037f9faef6a49dab7ef14ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==2.7.0\n",
        "!pip install seqeval"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configure model"
      ],
      "metadata": {
        "id": "AqfHHsyxmD3n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input: train.tsv, dev.tsv and test.tsv + labels file"
      ],
      "metadata": {
        "id": "Vk0SSH1dnOrR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7j4oKv_vDI9A",
        "outputId": "a8d66bc3-6adb-434a-8290-dc9d531f702b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "04/18/2022 19:54:42 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "04/18/2022 19:54:42 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmptvxci83g\n",
            "Downloading: 100% 433/433 [00:00<00:00, 314kB/s]\n",
            "04/18/2022 19:54:43 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json in cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "04/18/2022 19:54:43 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "04/18/2022 19:54:43 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "04/18/2022 19:54:43 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"_num_labels\": 25,\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": null,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"O\",\n",
            "    \"1\": \"I-SERVICE#GENERAL\",\n",
            "    \"10\": \"I-DRINKS#QUALITY\",\n",
            "    \"11\": \"I-DRINKS#PRICES\",\n",
            "    \"12\": \"I-AMBIENCE#GENERAL\",\n",
            "    \"13\": \"B-SERVICE#GENERAL\",\n",
            "    \"14\": \"B-RESTAURANT#PRICES\",\n",
            "    \"15\": \"B-RESTAURANT#MISCELLANEOUS\",\n",
            "    \"16\": \"B-RESTAURANT#GENERAL\",\n",
            "    \"17\": \"B-LOCATION#GENERAL\",\n",
            "    \"18\": \"B-FOOD#STYLE_OPTIONS\",\n",
            "    \"19\": \"B-FOOD#QUALITY\",\n",
            "    \"2\": \"I-RESTAURANT#PRICES\",\n",
            "    \"20\": \"B-FOOD#PRICES\",\n",
            "    \"21\": \"B-DRINKS#STYLE_OPTIONS\",\n",
            "    \"22\": \"B-DRINKS#QUALITY\",\n",
            "    \"23\": \"B-DRINKS#PRICES\",\n",
            "    \"24\": \"B-AMBIENCE#GENERAL\",\n",
            "    \"3\": \"I-RESTAURANT#MISCELLANEOUS\",\n",
            "    \"4\": \"I-RESTAURANT#GENERAL\",\n",
            "    \"5\": \"I-LOCATION#GENERAL\",\n",
            "    \"6\": \"I-FOOD#STYLE_OPTIONS\",\n",
            "    \"7\": \"I-FOOD#QUALITY\",\n",
            "    \"8\": \"I-FOOD#PRICES\",\n",
            "    \"9\": \"I-DRINKS#STYLE_OPTIONS\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"B-AMBIENCE#GENERAL\": 24,\n",
            "    \"B-DRINKS#PRICES\": 23,\n",
            "    \"B-DRINKS#QUALITY\": 22,\n",
            "    \"B-DRINKS#STYLE_OPTIONS\": 21,\n",
            "    \"B-FOOD#PRICES\": 20,\n",
            "    \"B-FOOD#QUALITY\": 19,\n",
            "    \"B-FOOD#STYLE_OPTIONS\": 18,\n",
            "    \"B-LOCATION#GENERAL\": 17,\n",
            "    \"B-RESTAURANT#GENERAL\": 16,\n",
            "    \"B-RESTAURANT#MISCELLANEOUS\": 15,\n",
            "    \"B-RESTAURANT#PRICES\": 14,\n",
            "    \"B-SERVICE#GENERAL\": 13,\n",
            "    \"I-AMBIENCE#GENERAL\": 12,\n",
            "    \"I-DRINKS#PRICES\": 11,\n",
            "    \"I-DRINKS#QUALITY\": 10,\n",
            "    \"I-DRINKS#STYLE_OPTIONS\": 9,\n",
            "    \"I-FOOD#PRICES\": 8,\n",
            "    \"I-FOOD#QUALITY\": 7,\n",
            "    \"I-FOOD#STYLE_OPTIONS\": 6,\n",
            "    \"I-LOCATION#GENERAL\": 5,\n",
            "    \"I-RESTAURANT#GENERAL\": 4,\n",
            "    \"I-RESTAURANT#MISCELLANEOUS\": 3,\n",
            "    \"I-RESTAURANT#PRICES\": 2,\n",
            "    \"I-SERVICE#GENERAL\": 1,\n",
            "    \"O\": 0\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "04/18/2022 19:54:43 - INFO - __main__ -   Tokenizer arguments: {'do_lower_case': False}\n",
            "04/18/2022 19:54:43 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "04/18/2022 19:54:43 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": null,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "04/18/2022 19:54:43 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp993hlm7n\n",
            "Downloading: 100% 232k/232k [00:00<00:00, 2.53MB/s]\n",
            "04/18/2022 19:54:43 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt in cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "04/18/2022 19:54:43 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "04/18/2022 19:54:43 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "04/18/2022 19:54:43 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpsnc5xs22\n",
            "Downloading: 100% 440M/440M [00:11<00:00, 39.8MB/s]\n",
            "04/18/2022 19:54:55 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin in cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "04/18/2022 19:54:55 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "04/18/2022 19:54:55 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "04/18/2022 19:54:58 - INFO - transformers.modeling_utils -   Weights of BertForTokenClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
            "04/18/2022 19:54:58 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "04/18/2022 19:55:11 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir='/content/drive/MyDrive/TFM_Rosa-Maria/sequence-labelling/data/categories/ABSA_data', device=device(type='cuda'), do_eval=True, do_lower_case=False, do_predict=True, do_train=True, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, keep_accents=None, labels='/content/drive/MyDrive/TFM_Rosa-Maria/sequence-labelling/data/labels/categories-labels.txt', learning_rate=5e-05, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert-base-uncased', n_gpu=1, no_cuda=False, num_train_epochs=10.0, output_dir='/content/drive/MyDrive/TFM_Rosa-Maria/sequence-labelling/output/output-april-absa-categories-ten-bert/', overwrite_cache=True, overwrite_output_dir=True, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=32, save_steps=0, seed=42, server_ip='', server_port='', strip_accents=None, tokenizer_name='', use_fast=None, warmup_steps=0, weight_decay=0.0)\n",
            "04/18/2022 19:55:11 - INFO - __main__ -   Creating features from dataset file at /content/drive/MyDrive/TFM_Rosa-Maria/sequence-labelling/data/categories/ABSA_data\n",
            "04/18/2022 19:55:11 - INFO - utils_ner -   Writing example 0 of 2000\n",
            "04/18/2022 19:55:11 - INFO - utils_ner -   *** Example ***\n",
            "04/18/2022 19:55:11 - INFO - utils_ner -   guid: train-1\n",
            "04/18/2022 19:55:11 - INFO - utils_ner -   tokens: [CLS] [UNK] from previous posts this used to be a good place , but not any longer . [SEP]\n",
            "04/18/2022 19:55:11 - INFO - utils_ner -   input_ids: 101 100 2013 3025 8466 2023 2109 2000 2022 1037 2204 2173 1010 2021 2025 2151 2936 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 19:55:11 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 19:55:11 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 19:55:12 - INFO - utils_ner -   label_ids: -100 0 0 0 0 0 0 0 0 0 0 16 0 0 0 0 0 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "04/18/2022 19:55:12 - INFO - utils_ner -   *** Example ***\n",
            "04/18/2022 19:55:12 - INFO - utils_ner -   guid: train-2\n",
            "04/18/2022 19:55:12 - INFO - utils_ner -   tokens: [CLS] [UNK] , there were four of us , arrived at noon - the place was empty - and the staff acted like we were imposing on them and they were very rude . [SEP]\n",
            "04/18/2022 19:55:12 - INFO - utils_ner -   input_ids: 101 100 1010 2045 2020 2176 1997 2149 1010 3369 2012 11501 1011 1996 2173 2001 4064 1011 1998 1996 3095 6051 2066 2057 2020 16625 2006 2068 1998 2027 2020 2200 12726 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 19:55:12 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 19:55:12 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 19:55:12 - INFO - utils_ner -   label_ids: -100 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 13 0 0 0 0 0 0 0 0 0 0 0 0 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "04/18/2022 19:55:12 - INFO - utils_ner -   *** Example ***\n",
            "04/18/2022 19:55:12 - INFO - utils_ner -   guid: train-3\n",
            "04/18/2022 19:55:12 - INFO - utils_ner -   tokens: [CLS] [UNK] never brought us compliment ##ary noodles , ignored repeated requests for sugar , and threw our dishes on the table . [SEP]\n",
            "04/18/2022 19:55:12 - INFO - utils_ner -   input_ids: 101 100 2196 2716 2149 19394 5649 27130 1010 6439 5567 11186 2005 5699 1010 1998 4711 2256 10447 2006 1996 2795 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 19:55:12 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 19:55:12 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 19:55:12 - INFO - utils_ner -   label_ids: -100 0 0 0 0 0 -100 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "04/18/2022 19:55:12 - INFO - utils_ner -   *** Example ***\n",
            "04/18/2022 19:55:12 - INFO - utils_ner -   guid: train-4\n",
            "04/18/2022 19:55:12 - INFO - utils_ner -   tokens: [CLS] [UNK] food was lou ##sy - too sweet or too salty and the portions tiny . [SEP]\n",
            "04/18/2022 19:55:12 - INFO - utils_ner -   input_ids: 101 100 2833 2001 10223 6508 1011 2205 4086 2030 2205 23592 1998 1996 8810 4714 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 19:55:12 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 19:55:12 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 19:55:12 - INFO - utils_ner -   label_ids: -100 0 19 0 0 -100 0 0 0 0 0 0 0 0 18 0 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "04/18/2022 19:55:12 - INFO - utils_ner -   *** Example ***\n",
            "04/18/2022 19:55:12 - INFO - utils_ner -   guid: train-5\n",
            "04/18/2022 19:55:12 - INFO - utils_ner -   tokens: [CLS] [UNK] all that , they complained to me about the small tip . [SEP]\n",
            "04/18/2022 19:55:12 - INFO - utils_ner -   input_ids: 101 100 2035 2008 1010 2027 10865 2000 2033 2055 1996 2235 5955 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 19:55:12 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 19:55:12 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 19:55:12 - INFO - utils_ner -   label_ids: -100 0 0 0 0 0 0 0 0 0 0 0 0 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "04/18/2022 19:55:13 - INFO - __main__ -   Saving features into cached file /content/drive/MyDrive/TFM_Rosa-Maria/sequence-labelling/data/categories/ABSA_data/cached_train_bert-base-uncased_128\n",
            "04/18/2022 19:55:13 - INFO - __main__ -   ***** Running training *****\n",
            "04/18/2022 19:55:13 - INFO - __main__ -     Num examples = 2000\n",
            "04/18/2022 19:55:13 - INFO - __main__ -     Num Epochs = 10\n",
            "04/18/2022 19:55:13 - INFO - __main__ -     Instantaneous batch size per GPU = 32\n",
            "04/18/2022 19:55:13 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "04/18/2022 19:55:13 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
            "04/18/2022 19:55:13 - INFO - __main__ -     Total optimization steps = 630\n",
            "Epoch:   0% 0/10 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/63 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n",
            "\n",
            "Iteration:   2% 1/63 [00:01<01:36,  1.55s/it]\u001b[A\n",
            "Iteration:   3% 2/63 [00:02<01:22,  1.35s/it]\u001b[A\n",
            "Iteration:   5% 3/63 [00:03<01:16,  1.28s/it]\u001b[A\n",
            "Iteration:   6% 4/63 [00:05<01:12,  1.24s/it]\u001b[A\n",
            "Iteration:   8% 5/63 [00:06<01:10,  1.22s/it]\u001b[A\n",
            "Iteration:  10% 6/63 [00:07<01:08,  1.20s/it]\u001b[A\n",
            "Iteration:  11% 7/63 [00:08<01:06,  1.19s/it]\u001b[A\n",
            "Iteration:  13% 8/63 [00:09<01:05,  1.19s/it]\u001b[A\n",
            "Iteration:  14% 9/63 [00:11<01:04,  1.19s/it]\u001b[A\n",
            "Iteration:  16% 10/63 [00:12<01:02,  1.18s/it]\u001b[A\n",
            "Iteration:  17% 11/63 [00:13<01:01,  1.18s/it]\u001b[A\n",
            "Iteration:  19% 12/63 [00:14<01:00,  1.18s/it]\u001b[A\n",
            "Iteration:  21% 13/63 [00:15<00:59,  1.18s/it]\u001b[A\n",
            "Iteration:  22% 14/63 [00:16<00:57,  1.18s/it]\u001b[A\n",
            "Iteration:  24% 15/63 [00:18<00:56,  1.18s/it]\u001b[A\n",
            "Iteration:  25% 16/63 [00:19<00:55,  1.18s/it]\u001b[A\n",
            "Iteration:  27% 17/63 [00:20<00:54,  1.18s/it]\u001b[A\n",
            "Iteration:  29% 18/63 [00:21<00:53,  1.18s/it]\u001b[A\n",
            "Iteration:  30% 19/63 [00:22<00:52,  1.18s/it]\u001b[A\n",
            "Iteration:  32% 20/63 [00:24<00:50,  1.18s/it]\u001b[A\n",
            "Iteration:  33% 21/63 [00:25<00:49,  1.19s/it]\u001b[A\n",
            "Iteration:  35% 22/63 [00:26<00:48,  1.19s/it]\u001b[A\n",
            "Iteration:  37% 23/63 [00:27<00:47,  1.19s/it]\u001b[A\n",
            "Iteration:  38% 24/63 [00:28<00:46,  1.19s/it]\u001b[A\n",
            "Iteration:  40% 25/63 [00:29<00:45,  1.19s/it]\u001b[A\n",
            "Iteration:  41% 26/63 [00:31<00:44,  1.19s/it]\u001b[A\n",
            "Iteration:  43% 27/63 [00:32<00:42,  1.19s/it]\u001b[A\n",
            "Iteration:  44% 28/63 [00:33<00:41,  1.19s/it]\u001b[A\n",
            "Iteration:  46% 29/63 [00:34<00:40,  1.19s/it]\u001b[A\n",
            "Iteration:  48% 30/63 [00:35<00:39,  1.19s/it]\u001b[A\n",
            "Iteration:  49% 31/63 [00:37<00:38,  1.19s/it]\u001b[A\n",
            "Iteration:  51% 32/63 [00:38<00:36,  1.19s/it]\u001b[A\n",
            "Iteration:  52% 33/63 [00:39<00:35,  1.19s/it]\u001b[A\n",
            "Iteration:  54% 34/63 [00:40<00:34,  1.19s/it]\u001b[A\n",
            "Iteration:  56% 35/63 [00:41<00:33,  1.19s/it]\u001b[A\n",
            "Iteration:  57% 36/63 [00:43<00:32,  1.19s/it]\u001b[A\n",
            "Iteration:  59% 37/63 [00:44<00:30,  1.19s/it]\u001b[A\n",
            "Iteration:  60% 38/63 [00:45<00:29,  1.19s/it]\u001b[A\n",
            "Iteration:  62% 39/63 [00:46<00:28,  1.19s/it]\u001b[A\n",
            "Iteration:  63% 40/63 [00:47<00:27,  1.19s/it]\u001b[A\n",
            "Iteration:  65% 41/63 [00:49<00:26,  1.19s/it]\u001b[A\n",
            "Iteration:  67% 42/63 [00:50<00:25,  1.19s/it]\u001b[A\n",
            "Iteration:  68% 43/63 [00:51<00:23,  1.19s/it]\u001b[A\n",
            "Iteration:  70% 44/63 [00:52<00:22,  1.19s/it]\u001b[A\n",
            "Iteration:  71% 45/63 [00:53<00:21,  1.19s/it]\u001b[A\n",
            "Iteration:  73% 46/63 [00:54<00:20,  1.19s/it]\u001b[A\n",
            "Iteration:  75% 47/63 [00:56<00:19,  1.19s/it]\u001b[A\n",
            "Iteration:  76% 48/63 [00:57<00:17,  1.19s/it]\u001b[A\n",
            "Iteration:  78% 49/63 [00:58<00:16,  1.19s/it]\u001b[A\n",
            "Iteration:  79% 50/63 [00:59<00:15,  1.19s/it]\u001b[A\n",
            "Iteration:  81% 51/63 [01:00<00:14,  1.20s/it]\u001b[A\n",
            "Iteration:  83% 52/63 [01:02<00:13,  1.20s/it]\u001b[A\n",
            "Iteration:  84% 53/63 [01:03<00:11,  1.20s/it]\u001b[A\n",
            "Iteration:  86% 54/63 [01:04<00:10,  1.19s/it]\u001b[A\n",
            "Iteration:  87% 55/63 [01:05<00:09,  1.20s/it]\u001b[A\n",
            "Iteration:  89% 56/63 [01:06<00:08,  1.20s/it]\u001b[A\n",
            "Iteration:  90% 57/63 [01:08<00:07,  1.20s/it]\u001b[A\n",
            "Iteration:  92% 58/63 [01:09<00:05,  1.20s/it]\u001b[A\n",
            "Iteration:  94% 59/63 [01:10<00:04,  1.20s/it]\u001b[A\n",
            "Iteration:  95% 60/63 [01:11<00:03,  1.20s/it]\u001b[A\n",
            "Iteration:  97% 61/63 [01:12<00:02,  1.20s/it]\u001b[A\n",
            "Iteration:  98% 62/63 [01:14<00:01,  1.20s/it]\u001b[A\n",
            "Iteration: 100% 63/63 [01:14<00:00,  1.19s/it]\n",
            "Epoch:  10% 1/10 [01:14<11:13, 74.80s/it]\n",
            "Iteration:   0% 0/63 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   2% 1/63 [00:01<01:13,  1.19s/it]\u001b[A\n",
            "Iteration:   3% 2/63 [00:02<01:12,  1.19s/it]\u001b[A\n",
            "Iteration:   5% 3/63 [00:03<01:11,  1.20s/it]\u001b[A\n",
            "Iteration:   6% 4/63 [00:04<01:10,  1.20s/it]\u001b[A\n",
            "Iteration:   8% 5/63 [00:05<01:09,  1.19s/it]\u001b[A\n",
            "Iteration:  10% 6/63 [00:07<01:08,  1.19s/it]\u001b[A\n",
            "Iteration:  11% 7/63 [00:08<01:06,  1.20s/it]\u001b[A\n",
            "Iteration:  13% 8/63 [00:09<01:05,  1.20s/it]\u001b[A\n",
            "Iteration:  14% 9/63 [00:10<01:04,  1.20s/it]\u001b[A\n",
            "Iteration:  16% 10/63 [00:11<01:03,  1.20s/it]\u001b[A\n",
            "Iteration:  17% 11/63 [00:13<01:02,  1.20s/it]\u001b[A\n",
            "Iteration:  19% 12/63 [00:14<01:01,  1.20s/it]\u001b[A\n",
            "Iteration:  21% 13/63 [00:15<00:59,  1.20s/it]\u001b[A\n",
            "Iteration:  22% 14/63 [00:16<00:58,  1.20s/it]\u001b[A\n",
            "Iteration:  24% 15/63 [00:17<00:57,  1.20s/it]\u001b[A\n",
            "Iteration:  25% 16/63 [00:19<00:56,  1.20s/it]\u001b[A\n",
            "Iteration:  27% 17/63 [00:20<00:55,  1.20s/it]\u001b[A\n",
            "Iteration:  29% 18/63 [00:21<00:53,  1.20s/it]\u001b[A\n",
            "Iteration:  30% 19/63 [00:22<00:52,  1.20s/it]\u001b[A\n",
            "Iteration:  32% 20/63 [00:23<00:51,  1.20s/it]\u001b[A\n",
            "Iteration:  33% 21/63 [00:25<00:50,  1.20s/it]\u001b[A\n",
            "Iteration:  35% 22/63 [00:26<00:49,  1.20s/it]\u001b[A\n",
            "Iteration:  37% 23/63 [00:27<00:48,  1.20s/it]\u001b[A\n",
            "Iteration:  38% 24/63 [00:28<00:46,  1.20s/it]\u001b[A\n",
            "Iteration:  40% 25/63 [00:29<00:45,  1.20s/it]\u001b[A\n",
            "Iteration:  41% 26/63 [00:31<00:44,  1.20s/it]\u001b[A\n",
            "Iteration:  43% 27/63 [00:32<00:43,  1.20s/it]\u001b[A\n",
            "Iteration:  44% 28/63 [00:33<00:41,  1.20s/it]\u001b[A\n",
            "Iteration:  46% 29/63 [00:34<00:40,  1.20s/it]\u001b[A\n",
            "Iteration:  48% 30/63 [00:35<00:39,  1.20s/it]\u001b[A\n",
            "Iteration:  49% 31/63 [00:37<00:38,  1.20s/it]\u001b[A\n",
            "Iteration:  51% 32/63 [00:38<00:37,  1.20s/it]\u001b[A\n",
            "Iteration:  52% 33/63 [00:39<00:35,  1.20s/it]\u001b[A\n",
            "Iteration:  54% 34/63 [00:40<00:34,  1.20s/it]\u001b[A\n",
            "Iteration:  56% 35/63 [00:41<00:33,  1.20s/it]\u001b[A\n",
            "Iteration:  57% 36/63 [00:43<00:32,  1.20s/it]\u001b[A\n",
            "Iteration:  59% 37/63 [00:44<00:31,  1.20s/it]\u001b[A\n",
            "Iteration:  60% 38/63 [00:45<00:29,  1.20s/it]\u001b[A\n",
            "Iteration:  62% 39/63 [00:46<00:28,  1.20s/it]\u001b[A\n",
            "Iteration:  63% 40/63 [00:47<00:27,  1.20s/it]\u001b[A\n",
            "Iteration:  65% 41/63 [00:49<00:26,  1.20s/it]\u001b[A\n",
            "Iteration:  67% 42/63 [00:50<00:25,  1.20s/it]\u001b[A\n",
            "Iteration:  68% 43/63 [00:51<00:23,  1.20s/it]\u001b[A\n",
            "Iteration:  70% 44/63 [00:52<00:22,  1.20s/it]\u001b[A\n",
            "Iteration:  71% 45/63 [00:53<00:21,  1.20s/it]\u001b[A\n",
            "Iteration:  73% 46/63 [00:55<00:20,  1.20s/it]\u001b[A\n",
            "Iteration:  75% 47/63 [00:56<00:19,  1.20s/it]\u001b[A\n",
            "Iteration:  76% 48/63 [00:57<00:17,  1.20s/it]\u001b[A\n",
            "Iteration:  78% 49/63 [00:58<00:16,  1.20s/it]\u001b[A\n",
            "Iteration:  79% 50/63 [00:59<00:15,  1.19s/it]\u001b[A\n",
            "Iteration:  81% 51/63 [01:01<00:14,  1.20s/it]\u001b[A\n",
            "Iteration:  83% 52/63 [01:02<00:13,  1.20s/it]\u001b[A\n",
            "Iteration:  84% 53/63 [01:03<00:12,  1.20s/it]\u001b[A\n",
            "Iteration:  86% 54/63 [01:04<00:10,  1.20s/it]\u001b[A\n",
            "Iteration:  87% 55/63 [01:05<00:09,  1.20s/it]\u001b[A\n",
            "Iteration:  89% 56/63 [01:07<00:08,  1.20s/it]\u001b[A\n",
            "Iteration:  90% 57/63 [01:08<00:07,  1.20s/it]\u001b[A\n",
            "Iteration:  92% 58/63 [01:09<00:06,  1.20s/it]\u001b[A\n",
            "Iteration:  94% 59/63 [01:10<00:04,  1.20s/it]\u001b[A\n",
            "Iteration:  95% 60/63 [01:11<00:03,  1.20s/it]\u001b[A\n",
            "Iteration:  97% 61/63 [01:13<00:02,  1.20s/it]\u001b[A\n",
            "Iteration:  98% 62/63 [01:14<00:01,  1.20s/it]\u001b[A\n",
            "Iteration: 100% 63/63 [01:14<00:00,  1.19s/it]\n",
            "Epoch:  20% 2/10 [02:29<09:58, 74.87s/it]\n",
            "Iteration:   0% 0/63 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   2% 1/63 [00:01<01:14,  1.19s/it]\u001b[A\n",
            "Iteration:   3% 2/63 [00:02<01:12,  1.20s/it]\u001b[A\n",
            "Iteration:   5% 3/63 [00:03<01:11,  1.20s/it]\u001b[A\n",
            "Iteration:   6% 4/63 [00:04<01:10,  1.20s/it]\u001b[A\n",
            "Iteration:   8% 5/63 [00:05<01:09,  1.20s/it]\u001b[A\n",
            "Iteration:  10% 6/63 [00:07<01:08,  1.20s/it]\u001b[A\n",
            "Iteration:  11% 7/63 [00:08<01:07,  1.20s/it]\u001b[A\n",
            "Iteration:  13% 8/63 [00:09<01:06,  1.20s/it]\u001b[A\n",
            "Iteration:  14% 9/63 [00:10<01:04,  1.20s/it]\u001b[A\n",
            "Iteration:  16% 10/63 [00:11<01:03,  1.20s/it]\u001b[A\n",
            "Iteration:  17% 11/63 [00:13<01:02,  1.20s/it]\u001b[A\n",
            "Iteration:  19% 12/63 [00:14<01:01,  1.20s/it]\u001b[A\n",
            "Iteration:  21% 13/63 [00:15<00:59,  1.20s/it]\u001b[A\n",
            "Iteration:  22% 14/63 [00:16<00:58,  1.20s/it]\u001b[A\n",
            "Iteration:  24% 15/63 [00:17<00:57,  1.20s/it]\u001b[A\n",
            "Iteration:  25% 16/63 [00:19<00:56,  1.20s/it]\u001b[A\n",
            "Iteration:  27% 17/63 [00:20<00:55,  1.20s/it]\u001b[A\n",
            "Iteration:  29% 18/63 [00:21<00:53,  1.20s/it]\u001b[A\n",
            "Iteration:  30% 19/63 [00:22<00:52,  1.20s/it]\u001b[A\n",
            "Iteration:  32% 20/63 [00:23<00:51,  1.20s/it]\u001b[A\n",
            "Iteration:  33% 21/63 [00:25<00:50,  1.20s/it]\u001b[A\n",
            "Iteration:  35% 22/63 [00:26<00:49,  1.20s/it]\u001b[A\n",
            "Iteration:  37% 23/63 [00:27<00:48,  1.20s/it]\u001b[A\n",
            "Iteration:  38% 24/63 [00:28<00:46,  1.20s/it]\u001b[A\n",
            "Iteration:  40% 25/63 [00:29<00:45,  1.20s/it]\u001b[A\n",
            "Iteration:  41% 26/63 [00:31<00:44,  1.20s/it]\u001b[A\n",
            "Iteration:  43% 27/63 [00:32<00:43,  1.20s/it]\u001b[A\n",
            "Iteration:  44% 28/63 [00:33<00:41,  1.20s/it]\u001b[A\n",
            "Iteration:  46% 29/63 [00:34<00:40,  1.20s/it]\u001b[A\n",
            "Iteration:  48% 30/63 [00:35<00:39,  1.20s/it]\u001b[A\n",
            "Iteration:  49% 31/63 [00:37<00:38,  1.20s/it]\u001b[A\n",
            "Iteration:  51% 32/63 [00:38<00:37,  1.20s/it]\u001b[A\n",
            "Iteration:  52% 33/63 [00:39<00:35,  1.20s/it]\u001b[A\n",
            "Iteration:  54% 34/63 [00:40<00:34,  1.20s/it]\u001b[A\n",
            "Iteration:  56% 35/63 [00:41<00:33,  1.20s/it]\u001b[A\n",
            "Iteration:  57% 36/63 [00:43<00:32,  1.20s/it]\u001b[A\n",
            "Iteration:  59% 37/63 [00:44<00:31,  1.20s/it]\u001b[A\n",
            "Iteration:  60% 38/63 [00:45<00:29,  1.20s/it]\u001b[A\n",
            "Iteration:  62% 39/63 [00:46<00:28,  1.20s/it]\u001b[A\n",
            "Iteration:  63% 40/63 [00:47<00:27,  1.20s/it]\u001b[A\n",
            "Iteration:  65% 41/63 [00:49<00:26,  1.20s/it]\u001b[A\n",
            "Iteration:  67% 42/63 [00:50<00:25,  1.20s/it]\u001b[A\n",
            "Iteration:  68% 43/63 [00:51<00:23,  1.20s/it]\u001b[A\n",
            "Iteration:  70% 44/63 [00:52<00:22,  1.20s/it]\u001b[A\n",
            "Iteration:  71% 45/63 [00:53<00:21,  1.20s/it]\u001b[A\n",
            "Iteration:  73% 46/63 [00:55<00:20,  1.20s/it]\u001b[A\n",
            "Iteration:  75% 47/63 [00:56<00:19,  1.20s/it]\u001b[A\n",
            "Iteration:  76% 48/63 [00:57<00:17,  1.20s/it]\u001b[A\n",
            "Iteration:  78% 49/63 [00:58<00:16,  1.20s/it]\u001b[A\n",
            "Iteration:  79% 50/63 [00:59<00:15,  1.20s/it]\u001b[A\n",
            "Iteration:  81% 51/63 [01:01<00:14,  1.20s/it]\u001b[A\n",
            "Iteration:  83% 52/63 [01:02<00:13,  1.20s/it]\u001b[A\n",
            "Iteration:  84% 53/63 [01:03<00:11,  1.20s/it]\u001b[A\n",
            "Iteration:  86% 54/63 [01:04<00:10,  1.20s/it]\u001b[A\n",
            "Iteration:  87% 55/63 [01:05<00:09,  1.20s/it]\u001b[A\n",
            "Iteration:  89% 56/63 [01:07<00:08,  1.20s/it]\u001b[A\n",
            "Iteration:  90% 57/63 [01:08<00:07,  1.20s/it]\u001b[A\n",
            "Iteration:  92% 58/63 [01:09<00:05,  1.20s/it]\u001b[A\n",
            "Iteration:  94% 59/63 [01:10<00:04,  1.19s/it]\u001b[A\n",
            "Iteration:  95% 60/63 [01:11<00:03,  1.20s/it]\u001b[A\n",
            "Iteration:  97% 61/63 [01:13<00:02,  1.20s/it]\u001b[A\n",
            "Iteration:  98% 62/63 [01:14<00:01,  1.20s/it]\u001b[A\n",
            "Iteration: 100% 63/63 [01:14<00:00,  1.19s/it]\n",
            "Epoch:  30% 3/10 [03:44<08:44, 74.91s/it]\n",
            "Iteration:   0% 0/63 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   2% 1/63 [00:01<01:14,  1.20s/it]\u001b[A\n",
            "Iteration:   3% 2/63 [00:02<01:13,  1.20s/it]\u001b[A\n",
            "Iteration:   5% 3/63 [00:03<01:11,  1.20s/it]\u001b[A\n",
            "Iteration:   6% 4/63 [00:04<01:10,  1.19s/it]\u001b[A\n",
            "Iteration:   8% 5/63 [00:05<01:09,  1.20s/it]\u001b[A\n",
            "Iteration:  10% 6/63 [00:07<01:08,  1.19s/it]\u001b[A\n",
            "Iteration:  11% 7/63 [00:08<01:06,  1.20s/it]\u001b[A\n",
            "Iteration:  13% 8/63 [00:09<01:05,  1.20s/it]\u001b[A\n",
            "Iteration:  14% 9/63 [00:10<01:04,  1.20s/it]\u001b[A\n",
            "Iteration:  16% 10/63 [00:11<01:03,  1.20s/it]\u001b[A\n",
            "Iteration:  17% 11/63 [00:13<01:02,  1.20s/it]\u001b[A\n",
            "Iteration:  19% 12/63 [00:14<01:01,  1.20s/it]\u001b[A\n",
            "Iteration:  21% 13/63 [00:15<01:00,  1.20s/it]\u001b[A\n",
            "Iteration:  22% 14/63 [00:16<00:58,  1.20s/it]\u001b[A\n",
            "Iteration:  24% 15/63 [00:17<00:57,  1.20s/it]\u001b[A\n",
            "Iteration:  25% 16/63 [00:19<00:56,  1.20s/it]\u001b[A\n",
            "Iteration:  27% 17/63 [00:20<00:55,  1.20s/it]\u001b[A\n",
            "Iteration:  29% 18/63 [00:21<00:53,  1.20s/it]\u001b[A\n",
            "Iteration:  30% 19/63 [00:22<00:52,  1.20s/it]\u001b[A\n",
            "Iteration:  32% 20/63 [00:23<00:51,  1.20s/it]\u001b[A\n",
            "Iteration:  33% 21/63 [00:25<00:50,  1.20s/it]\u001b[A\n",
            "Iteration:  35% 22/63 [00:26<00:49,  1.20s/it]\u001b[A\n",
            "Iteration:  37% 23/63 [00:27<00:47,  1.20s/it]\u001b[A\n",
            "Iteration:  38% 24/63 [00:28<00:46,  1.20s/it]\u001b[A\n",
            "Iteration:  40% 25/63 [00:29<00:45,  1.20s/it]\u001b[A\n",
            "Iteration:  41% 26/63 [00:31<00:44,  1.20s/it]\u001b[A\n",
            "Iteration:  43% 27/63 [00:32<00:43,  1.20s/it]\u001b[A\n",
            "Iteration:  44% 28/63 [00:33<00:41,  1.20s/it]\u001b[A\n",
            "Iteration:  46% 29/63 [00:34<00:40,  1.20s/it]\u001b[A\n",
            "Iteration:  48% 30/63 [00:35<00:39,  1.20s/it]\u001b[A\n",
            "Iteration:  49% 31/63 [00:37<00:38,  1.20s/it]\u001b[A\n",
            "Iteration:  51% 32/63 [00:38<00:37,  1.20s/it]\u001b[A\n",
            "Iteration:  52% 33/63 [00:39<00:35,  1.20s/it]\u001b[A\n",
            "Iteration:  54% 34/63 [00:40<00:34,  1.20s/it]\u001b[A\n",
            "Iteration:  56% 35/63 [00:41<00:33,  1.20s/it]\u001b[A\n",
            "Iteration:  57% 36/63 [00:43<00:32,  1.20s/it]\u001b[A\n",
            "Iteration:  59% 37/63 [00:44<00:31,  1.20s/it]\u001b[A\n",
            "Iteration:  60% 38/63 [00:45<00:29,  1.20s/it]\u001b[A\n",
            "Iteration:  62% 39/63 [00:46<00:28,  1.20s/it]\u001b[A\n",
            "Iteration:  63% 40/63 [00:47<00:27,  1.20s/it]\u001b[A\n",
            "Iteration:  65% 41/63 [00:49<00:26,  1.20s/it]\u001b[A\n",
            "Iteration:  67% 42/63 [00:50<00:25,  1.20s/it]\u001b[A\n",
            "Iteration:  68% 43/63 [00:51<00:23,  1.20s/it]\u001b[A\n",
            "Iteration:  70% 44/63 [00:52<00:22,  1.20s/it]\u001b[A\n",
            "Iteration:  71% 45/63 [00:53<00:21,  1.20s/it]\u001b[A\n",
            "Iteration:  73% 46/63 [00:55<00:20,  1.20s/it]\u001b[A\n",
            "Iteration:  75% 47/63 [00:56<00:19,  1.20s/it]\u001b[A\n",
            "Iteration:  76% 48/63 [00:57<00:17,  1.20s/it]\u001b[A\n",
            "Iteration:  78% 49/63 [00:58<00:16,  1.20s/it]\u001b[A\n",
            "Iteration:  79% 50/63 [00:59<00:15,  1.20s/it]\u001b[A\n",
            "Iteration:  81% 51/63 [01:01<00:14,  1.20s/it]\u001b[A\n",
            "Iteration:  83% 52/63 [01:02<00:13,  1.20s/it]\u001b[A\n",
            "Iteration:  84% 53/63 [01:03<00:11,  1.20s/it]\u001b[A\n",
            "Iteration:  86% 54/63 [01:04<00:10,  1.20s/it]\u001b[A\n",
            "Iteration:  87% 55/63 [01:05<00:09,  1.20s/it]\u001b[A\n",
            "Iteration:  89% 56/63 [01:07<00:08,  1.21s/it]\u001b[A\n",
            "Iteration:  90% 57/63 [01:08<00:07,  1.20s/it]\u001b[A\n",
            "Iteration:  92% 58/63 [01:09<00:06,  1.21s/it]\u001b[A\n",
            "Iteration:  94% 59/63 [01:10<00:04,  1.20s/it]\u001b[A\n",
            "Iteration:  95% 60/63 [01:11<00:03,  1.20s/it]\u001b[A\n",
            "Iteration:  97% 61/63 [01:13<00:02,  1.20s/it]\u001b[A\n",
            "Iteration:  98% 62/63 [01:14<00:01,  1.20s/it]\u001b[A\n",
            "Iteration: 100% 63/63 [01:14<00:00,  1.19s/it]\n",
            "Epoch:  40% 4/10 [04:59<07:29, 74.95s/it]\n",
            "Iteration:   0% 0/63 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   2% 1/63 [00:01<01:14,  1.21s/it]\u001b[A\n",
            "Iteration:   3% 2/63 [00:02<01:13,  1.21s/it]\u001b[A\n",
            "Iteration:   5% 3/63 [00:03<01:12,  1.21s/it]\u001b[A\n",
            "Iteration:   6% 4/63 [00:04<01:11,  1.21s/it]\u001b[A\n",
            "Iteration:   8% 5/63 [00:06<01:09,  1.21s/it]\u001b[A\n",
            "Iteration:  10% 6/63 [00:07<01:08,  1.21s/it]\u001b[A\n",
            "Iteration:  11% 7/63 [00:08<01:07,  1.21s/it]\u001b[A\n",
            "Iteration:  13% 8/63 [00:09<01:06,  1.21s/it]\u001b[A\n",
            "Iteration:  14% 9/63 [00:10<01:05,  1.21s/it]\u001b[A\n",
            "Iteration:  16% 10/63 [00:12<01:04,  1.21s/it]\u001b[A\n",
            "Iteration:  17% 11/63 [00:13<01:03,  1.21s/it]\u001b[A\n",
            "Iteration:  19% 12/63 [00:14<01:01,  1.21s/it]\u001b[A\n",
            "Iteration:  21% 13/63 [00:15<01:00,  1.21s/it]\u001b[A\n",
            "Iteration:  22% 14/63 [00:16<00:59,  1.21s/it]\u001b[A\n",
            "Iteration:  24% 15/63 [00:18<00:58,  1.21s/it]\u001b[A\n",
            "Iteration:  25% 16/63 [00:19<00:57,  1.21s/it]\u001b[A\n",
            "Iteration:  27% 17/63 [00:20<00:55,  1.21s/it]\u001b[A\n",
            "Iteration:  29% 18/63 [00:21<00:54,  1.22s/it]\u001b[A\n",
            "Iteration:  30% 19/63 [00:23<00:53,  1.22s/it]\u001b[A\n",
            "Iteration:  32% 20/63 [00:24<00:52,  1.22s/it]\u001b[A\n",
            "Iteration:  33% 21/63 [00:25<00:51,  1.22s/it]\u001b[A\n",
            "Iteration:  35% 22/63 [00:26<00:49,  1.22s/it]\u001b[A\n",
            "Iteration:  37% 23/63 [00:27<00:48,  1.22s/it]\u001b[A\n",
            "Iteration:  38% 24/63 [00:29<00:47,  1.22s/it]\u001b[A\n",
            "Iteration:  40% 25/63 [00:30<00:46,  1.22s/it]\u001b[A\n",
            "Iteration:  41% 26/63 [00:31<00:45,  1.22s/it]\u001b[A\n",
            "Iteration:  43% 27/63 [00:32<00:44,  1.22s/it]\u001b[A\n",
            "Iteration:  44% 28/63 [00:34<00:42,  1.23s/it]\u001b[A\n",
            "Iteration:  46% 29/63 [00:35<00:41,  1.22s/it]\u001b[A\n",
            "Iteration:  48% 30/63 [00:36<00:40,  1.23s/it]\u001b[A\n",
            "Iteration:  49% 31/63 [00:37<00:39,  1.23s/it]\u001b[A\n",
            "Iteration:  51% 32/63 [00:38<00:38,  1.23s/it]\u001b[A\n",
            "Iteration:  52% 33/63 [00:40<00:36,  1.23s/it]\u001b[A\n",
            "Iteration:  54% 34/63 [00:41<00:35,  1.23s/it]\u001b[A\n",
            "Iteration:  56% 35/63 [00:42<00:34,  1.23s/it]\u001b[A\n",
            "Iteration:  57% 36/63 [00:43<00:33,  1.23s/it]\u001b[A\n",
            "Iteration:  59% 37/63 [00:45<00:32,  1.24s/it]\u001b[A\n",
            "Iteration:  60% 38/63 [00:46<00:30,  1.24s/it]\u001b[A\n",
            "Iteration:  62% 39/63 [00:47<00:29,  1.24s/it]\u001b[A\n",
            "Iteration:  63% 40/63 [00:48<00:28,  1.24s/it]\u001b[A\n",
            "Iteration:  65% 41/63 [00:50<00:27,  1.24s/it]\u001b[A\n",
            "Iteration:  67% 42/63 [00:51<00:25,  1.24s/it]\u001b[A\n",
            "Iteration:  68% 43/63 [00:52<00:24,  1.24s/it]\u001b[A\n",
            "Iteration:  70% 44/63 [00:53<00:23,  1.24s/it]\u001b[A\n",
            "Iteration:  71% 45/63 [00:55<00:22,  1.24s/it]\u001b[A\n",
            "Iteration:  73% 46/63 [00:56<00:20,  1.23s/it]\u001b[A\n",
            "Iteration:  75% 47/63 [00:57<00:19,  1.23s/it]\u001b[A\n",
            "Iteration:  76% 48/63 [00:58<00:18,  1.23s/it]\u001b[A\n",
            "Iteration:  78% 49/63 [00:59<00:17,  1.23s/it]\u001b[A\n",
            "Iteration:  79% 50/63 [01:01<00:16,  1.24s/it]\u001b[A\n",
            "Iteration:  81% 51/63 [01:02<00:14,  1.23s/it]\u001b[A\n",
            "Iteration:  83% 52/63 [01:03<00:13,  1.24s/it]\u001b[A\n",
            "Iteration:  84% 53/63 [01:04<00:12,  1.24s/it]\u001b[A\n",
            "Iteration:  86% 54/63 [01:06<00:11,  1.24s/it]\u001b[A\n",
            "Iteration:  87% 55/63 [01:07<00:09,  1.24s/it]\u001b[A\n",
            "Iteration:  89% 56/63 [01:08<00:08,  1.24s/it]\u001b[A\n",
            "Iteration:  90% 57/63 [01:09<00:07,  1.24s/it]\u001b[A\n",
            "Iteration:  92% 58/63 [01:11<00:06,  1.24s/it]\u001b[A\n",
            "Iteration:  94% 59/63 [01:12<00:04,  1.24s/it]\u001b[A\n",
            "Iteration:  95% 60/63 [01:13<00:03,  1.24s/it]\u001b[A\n",
            "Iteration:  97% 61/63 [01:14<00:02,  1.24s/it]\u001b[A\n",
            "Iteration:  98% 62/63 [01:16<00:01,  1.24s/it]\u001b[A\n",
            "Iteration: 100% 63/63 [01:16<00:00,  1.22s/it]\n",
            "Epoch:  50% 5/10 [06:16<06:17, 75.59s/it]\n",
            "Iteration:   0% 0/63 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   2% 1/63 [00:01<01:16,  1.24s/it]\u001b[A\n",
            "Iteration:   3% 2/63 [00:02<01:15,  1.23s/it]\u001b[A\n",
            "Iteration:   5% 3/63 [00:03<01:14,  1.24s/it]\u001b[A\n",
            "Iteration:   6% 4/63 [00:04<01:13,  1.24s/it]\u001b[A\n",
            "Iteration:   8% 5/63 [00:06<01:11,  1.24s/it]\u001b[A\n",
            "Iteration:  10% 6/63 [00:07<01:10,  1.24s/it]\u001b[A\n",
            "Iteration:  11% 7/63 [00:08<01:09,  1.24s/it]\u001b[A\n",
            "Iteration:  13% 8/63 [00:09<01:08,  1.24s/it]\u001b[A\n",
            "Iteration:  14% 9/63 [00:11<01:06,  1.24s/it]\u001b[A\n",
            "Iteration:  16% 10/63 [00:12<01:05,  1.24s/it]\u001b[A\n",
            "Iteration:  17% 11/63 [00:13<01:04,  1.24s/it]\u001b[A\n",
            "Iteration:  19% 12/63 [00:14<01:03,  1.24s/it]\u001b[A\n",
            "Iteration:  21% 13/63 [00:16<01:01,  1.24s/it]\u001b[A\n",
            "Iteration:  22% 14/63 [00:17<01:00,  1.24s/it]\u001b[A\n",
            "Iteration:  24% 15/63 [00:18<00:59,  1.24s/it]\u001b[A\n",
            "Iteration:  25% 16/63 [00:19<00:58,  1.24s/it]\u001b[A\n",
            "Iteration:  27% 17/63 [00:21<00:56,  1.24s/it]\u001b[A\n",
            "Iteration:  29% 18/63 [00:22<00:55,  1.24s/it]\u001b[A\n",
            "Iteration:  30% 19/63 [00:23<00:54,  1.24s/it]\u001b[A\n",
            "Iteration:  32% 20/63 [00:24<00:53,  1.24s/it]\u001b[A\n",
            "Iteration:  33% 21/63 [00:25<00:51,  1.24s/it]\u001b[A\n",
            "Iteration:  35% 22/63 [00:27<00:50,  1.24s/it]\u001b[A\n",
            "Iteration:  37% 23/63 [00:28<00:49,  1.24s/it]\u001b[A\n",
            "Iteration:  38% 24/63 [00:29<00:48,  1.24s/it]\u001b[A\n",
            "Iteration:  40% 25/63 [00:30<00:47,  1.24s/it]\u001b[A\n",
            "Iteration:  41% 26/63 [00:32<00:45,  1.24s/it]\u001b[A\n",
            "Iteration:  43% 27/63 [00:33<00:44,  1.24s/it]\u001b[A\n",
            "Iteration:  44% 28/63 [00:34<00:43,  1.25s/it]\u001b[A\n",
            "Iteration:  46% 29/63 [00:35<00:42,  1.24s/it]\u001b[A\n",
            "Iteration:  48% 30/63 [00:37<00:40,  1.24s/it]\u001b[A\n",
            "Iteration:  49% 31/63 [00:38<00:39,  1.24s/it]\u001b[A\n",
            "Iteration:  51% 32/63 [00:39<00:38,  1.24s/it]\u001b[A\n",
            "Iteration:  52% 33/63 [00:40<00:37,  1.24s/it]\u001b[A\n",
            "Iteration:  54% 34/63 [00:42<00:35,  1.24s/it]\u001b[A\n",
            "Iteration:  56% 35/63 [00:43<00:34,  1.24s/it]\u001b[A\n",
            "Iteration:  57% 36/63 [00:44<00:33,  1.24s/it]\u001b[A\n",
            "Iteration:  59% 37/63 [00:45<00:32,  1.24s/it]\u001b[A\n",
            "Iteration:  60% 38/63 [00:47<00:30,  1.24s/it]\u001b[A\n",
            "Iteration:  62% 39/63 [00:48<00:29,  1.24s/it]\u001b[A\n",
            "Iteration:  63% 40/63 [00:49<00:28,  1.24s/it]\u001b[A\n",
            "Iteration:  65% 41/63 [00:50<00:27,  1.24s/it]\u001b[A\n",
            "Iteration:  67% 42/63 [00:52<00:26,  1.24s/it]\u001b[A\n",
            "Iteration:  68% 43/63 [00:53<00:24,  1.24s/it]\u001b[A\n",
            "Iteration:  70% 44/63 [00:54<00:23,  1.24s/it]\u001b[A\n",
            "Iteration:  71% 45/63 [00:55<00:22,  1.24s/it]\u001b[A\n",
            "Iteration:  73% 46/63 [00:56<00:21,  1.24s/it]\u001b[A\n",
            "Iteration:  75% 47/63 [00:58<00:19,  1.24s/it]\u001b[A\n",
            "Iteration:  76% 48/63 [00:59<00:18,  1.24s/it]\u001b[A\n",
            "Iteration:  78% 49/63 [01:00<00:17,  1.24s/it]\u001b[A\n",
            "Iteration:  79% 50/63 [01:01<00:16,  1.24s/it]\u001b[A\n",
            "Iteration:  81% 51/63 [01:03<00:14,  1.24s/it]\u001b[A\n",
            "Iteration:  83% 52/63 [01:04<00:13,  1.24s/it]\u001b[A\n",
            "Iteration:  84% 53/63 [01:05<00:12,  1.24s/it]\u001b[A\n",
            "Iteration:  86% 54/63 [01:06<00:11,  1.24s/it]\u001b[A\n",
            "Iteration:  87% 55/63 [01:08<00:09,  1.24s/it]\u001b[A\n",
            "Iteration:  89% 56/63 [01:09<00:08,  1.24s/it]\u001b[A\n",
            "Iteration:  90% 57/63 [01:10<00:07,  1.23s/it]\u001b[A\n",
            "Iteration:  92% 58/63 [01:11<00:06,  1.24s/it]\u001b[A\n",
            "Iteration:  94% 59/63 [01:13<00:04,  1.24s/it]\u001b[A\n",
            "Iteration:  95% 60/63 [01:14<00:03,  1.24s/it]\u001b[A\n",
            "Iteration:  97% 61/63 [01:15<00:02,  1.24s/it]\u001b[A\n",
            "Iteration:  98% 62/63 [01:16<00:01,  1.24s/it]\u001b[A\n",
            "Iteration: 100% 63/63 [01:17<00:00,  1.23s/it]\n",
            "Epoch:  60% 6/10 [07:33<05:04, 76.23s/it]\n",
            "Iteration:   0% 0/63 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   2% 1/63 [00:01<01:16,  1.24s/it]\u001b[A\n",
            "Iteration:   3% 2/63 [00:02<01:15,  1.24s/it]\u001b[A\n",
            "Iteration:   5% 3/63 [00:03<01:14,  1.24s/it]\u001b[A\n",
            "Iteration:   6% 4/63 [00:04<01:12,  1.24s/it]\u001b[A\n",
            "Iteration:   8% 5/63 [00:06<01:11,  1.23s/it]\u001b[A\n",
            "Iteration:  10% 6/63 [00:07<01:10,  1.24s/it]\u001b[A\n",
            "Iteration:  11% 7/63 [00:08<01:09,  1.24s/it]\u001b[A\n",
            "Iteration:  13% 8/63 [00:09<01:07,  1.23s/it]\u001b[A\n",
            "Iteration:  14% 9/63 [00:11<01:06,  1.24s/it]\u001b[A\n",
            "Iteration:  16% 10/63 [00:12<01:05,  1.24s/it]\u001b[A\n",
            "Iteration:  17% 11/63 [00:13<01:04,  1.24s/it]\u001b[A\n",
            "Iteration:  19% 12/63 [00:14<01:03,  1.24s/it]\u001b[A\n",
            "Iteration:  21% 13/63 [00:16<01:01,  1.24s/it]\u001b[A\n",
            "Iteration:  22% 14/63 [00:17<01:00,  1.24s/it]\u001b[A\n",
            "Iteration:  24% 15/63 [00:18<00:59,  1.24s/it]\u001b[A\n",
            "Iteration:  25% 16/63 [00:19<00:58,  1.24s/it]\u001b[A\n",
            "Iteration:  27% 17/63 [00:21<00:57,  1.24s/it]\u001b[A\n",
            "Iteration:  29% 18/63 [00:22<00:55,  1.24s/it]\u001b[A\n",
            "Iteration:  30% 19/63 [00:23<00:54,  1.24s/it]\u001b[A\n",
            "Iteration:  32% 20/63 [00:24<00:53,  1.24s/it]\u001b[A\n",
            "Iteration:  33% 21/63 [00:26<00:52,  1.24s/it]\u001b[A\n",
            "Iteration:  35% 22/63 [00:27<00:50,  1.24s/it]\u001b[A\n",
            "Iteration:  37% 23/63 [00:28<00:49,  1.24s/it]\u001b[A\n",
            "Iteration:  38% 24/63 [00:29<00:48,  1.24s/it]\u001b[A\n",
            "Iteration:  40% 25/63 [00:30<00:47,  1.24s/it]\u001b[A\n",
            "Iteration:  41% 26/63 [00:32<00:45,  1.24s/it]\u001b[A\n",
            "Iteration:  43% 27/63 [00:33<00:44,  1.24s/it]\u001b[A\n",
            "Iteration:  44% 28/63 [00:34<00:43,  1.24s/it]\u001b[A\n",
            "Iteration:  46% 29/63 [00:35<00:41,  1.24s/it]\u001b[A\n",
            "Iteration:  48% 30/63 [00:37<00:40,  1.23s/it]\u001b[A\n",
            "Iteration:  49% 31/63 [00:38<00:39,  1.24s/it]\u001b[A\n",
            "Iteration:  51% 32/63 [00:39<00:38,  1.24s/it]\u001b[A\n",
            "Iteration:  52% 33/63 [00:40<00:37,  1.24s/it]\u001b[A\n",
            "Iteration:  54% 34/63 [00:42<00:35,  1.24s/it]\u001b[A\n",
            "Iteration:  56% 35/63 [00:43<00:34,  1.24s/it]\u001b[A\n",
            "Iteration:  57% 36/63 [00:44<00:33,  1.24s/it]\u001b[A\n",
            "Iteration:  59% 37/63 [00:45<00:32,  1.24s/it]\u001b[A\n",
            "Iteration:  60% 38/63 [00:47<00:31,  1.24s/it]\u001b[A\n",
            "Iteration:  62% 39/63 [00:48<00:29,  1.24s/it]\u001b[A\n",
            "Iteration:  63% 40/63 [00:49<00:28,  1.24s/it]\u001b[A\n",
            "Iteration:  65% 41/63 [00:50<00:27,  1.24s/it]\u001b[A\n",
            "Iteration:  67% 42/63 [00:52<00:26,  1.24s/it]\u001b[A\n",
            "Iteration:  68% 43/63 [00:53<00:24,  1.24s/it]\u001b[A\n",
            "Iteration:  70% 44/63 [00:54<00:23,  1.24s/it]\u001b[A\n",
            "Iteration:  71% 45/63 [00:55<00:22,  1.24s/it]\u001b[A\n",
            "Iteration:  73% 46/63 [00:56<00:21,  1.24s/it]\u001b[A\n",
            "Iteration:  75% 47/63 [00:58<00:19,  1.23s/it]\u001b[A\n",
            "Iteration:  76% 48/63 [00:59<00:18,  1.24s/it]\u001b[A\n",
            "Iteration:  78% 49/63 [01:00<00:17,  1.24s/it]\u001b[A\n",
            "Iteration:  79% 50/63 [01:01<00:16,  1.24s/it]\u001b[A\n",
            "Iteration:  81% 51/63 [01:03<00:14,  1.24s/it]\u001b[A\n",
            "Iteration:  83% 52/63 [01:04<00:13,  1.24s/it]\u001b[A\n",
            "Iteration:  84% 53/63 [01:05<00:12,  1.24s/it]\u001b[A\n",
            "Iteration:  86% 54/63 [01:06<00:11,  1.24s/it]\u001b[A\n",
            "Iteration:  87% 55/63 [01:08<00:09,  1.24s/it]\u001b[A\n",
            "Iteration:  89% 56/63 [01:09<00:08,  1.24s/it]\u001b[A\n",
            "Iteration:  90% 57/63 [01:10<00:07,  1.24s/it]\u001b[A\n",
            "Iteration:  92% 58/63 [01:11<00:06,  1.24s/it]\u001b[A\n",
            "Iteration:  94% 59/63 [01:13<00:04,  1.24s/it]\u001b[A\n",
            "Iteration:  95% 60/63 [01:14<00:03,  1.24s/it]\u001b[A\n",
            "Iteration:  97% 61/63 [01:15<00:02,  1.24s/it]\u001b[A\n",
            "Iteration:  98% 62/63 [01:16<00:01,  1.24s/it]\u001b[A\n",
            "Iteration: 100% 63/63 [01:17<00:00,  1.23s/it]\n",
            "Epoch:  70% 7/10 [08:51<03:49, 76.63s/it]\n",
            "Iteration:   0% 0/63 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   2% 1/63 [00:01<01:16,  1.23s/it]\u001b[A\n",
            "Iteration:   3% 2/63 [00:02<01:15,  1.24s/it]\u001b[A\n",
            "Iteration:   5% 3/63 [00:03<01:14,  1.24s/it]\u001b[A\n",
            "Iteration:   6% 4/63 [00:04<01:13,  1.24s/it]\u001b[A\n",
            "Iteration:   8% 5/63 [00:06<01:11,  1.24s/it]\u001b[A\n",
            "Iteration:  10% 6/63 [00:07<01:10,  1.24s/it]\u001b[A\n",
            "Iteration:  11% 7/63 [00:08<01:09,  1.24s/it]\u001b[A\n",
            "Iteration:  13% 8/63 [00:09<01:08,  1.24s/it]\u001b[A\n",
            "Iteration:  14% 9/63 [00:11<01:06,  1.24s/it]\u001b[A\n",
            "Iteration:  16% 10/63 [00:12<01:05,  1.24s/it]\u001b[A\n",
            "Iteration:  17% 11/63 [00:13<01:04,  1.24s/it]\u001b[A\n",
            "Iteration:  19% 12/63 [00:14<01:03,  1.24s/it]\u001b[A\n",
            "Iteration:  21% 13/63 [00:16<01:01,  1.24s/it]\u001b[A\n",
            "Iteration:  22% 14/63 [00:17<01:00,  1.24s/it]\u001b[A\n",
            "Iteration:  24% 15/63 [00:18<00:59,  1.24s/it]\u001b[A\n",
            "Iteration:  25% 16/63 [00:19<00:58,  1.24s/it]\u001b[A\n",
            "Iteration:  27% 17/63 [00:21<00:56,  1.24s/it]\u001b[A\n",
            "Iteration:  29% 18/63 [00:22<00:55,  1.24s/it]\u001b[A\n",
            "Iteration:  30% 19/63 [00:23<00:54,  1.24s/it]\u001b[A\n",
            "Iteration:  32% 20/63 [00:24<00:53,  1.23s/it]\u001b[A\n",
            "Iteration:  33% 21/63 [00:25<00:51,  1.23s/it]\u001b[A\n",
            "Iteration:  35% 22/63 [00:27<00:50,  1.23s/it]\u001b[A\n",
            "Iteration:  37% 23/63 [00:28<00:49,  1.24s/it]\u001b[A\n",
            "Iteration:  38% 24/63 [00:29<00:48,  1.24s/it]\u001b[A\n",
            "Iteration:  40% 25/63 [00:30<00:47,  1.24s/it]\u001b[A\n",
            "Iteration:  41% 26/63 [00:32<00:45,  1.24s/it]\u001b[A\n",
            "Iteration:  43% 27/63 [00:33<00:44,  1.24s/it]\u001b[A\n",
            "Iteration:  44% 28/63 [00:34<00:43,  1.24s/it]\u001b[A\n",
            "Iteration:  46% 29/63 [00:35<00:42,  1.24s/it]\u001b[A\n",
            "Iteration:  48% 30/63 [00:37<00:40,  1.24s/it]\u001b[A\n",
            "Iteration:  49% 31/63 [00:38<00:39,  1.24s/it]\u001b[A\n",
            "Iteration:  51% 32/63 [00:39<00:38,  1.23s/it]\u001b[A\n",
            "Iteration:  52% 33/63 [00:40<00:37,  1.24s/it]\u001b[A\n",
            "Iteration:  54% 34/63 [00:42<00:35,  1.24s/it]\u001b[A\n",
            "Iteration:  56% 35/63 [00:43<00:34,  1.24s/it]\u001b[A\n",
            "Iteration:  57% 36/63 [00:44<00:33,  1.24s/it]\u001b[A\n",
            "Iteration:  59% 37/63 [00:45<00:32,  1.24s/it]\u001b[A\n",
            "Iteration:  60% 38/63 [00:47<00:30,  1.24s/it]\u001b[A\n",
            "Iteration:  62% 39/63 [00:48<00:29,  1.24s/it]\u001b[A\n",
            "Iteration:  63% 40/63 [00:49<00:28,  1.24s/it]\u001b[A\n",
            "Iteration:  65% 41/63 [00:50<00:27,  1.24s/it]\u001b[A\n",
            "Iteration:  67% 42/63 [00:51<00:25,  1.24s/it]\u001b[A\n",
            "Iteration:  68% 43/63 [00:53<00:24,  1.24s/it]\u001b[A\n",
            "Iteration:  70% 44/63 [00:54<00:23,  1.24s/it]\u001b[A\n",
            "Iteration:  71% 45/63 [00:55<00:22,  1.24s/it]\u001b[A\n",
            "Iteration:  73% 46/63 [00:56<00:21,  1.24s/it]\u001b[A\n",
            "Iteration:  75% 47/63 [00:58<00:19,  1.24s/it]\u001b[A\n",
            "Iteration:  76% 48/63 [00:59<00:18,  1.24s/it]\u001b[A\n",
            "Iteration:  78% 49/63 [01:00<00:17,  1.24s/it]\u001b[A\n",
            "Iteration:  79% 50/63 [01:01<00:16,  1.23s/it]\u001b[A\n",
            "Iteration:  81% 51/63 [01:03<00:14,  1.23s/it]\u001b[A\n",
            "Iteration:  83% 52/63 [01:04<00:13,  1.23s/it]\u001b[A\n",
            "Iteration:  84% 53/63 [01:05<00:12,  1.23s/it]\u001b[A\n",
            "Iteration:  86% 54/63 [01:06<00:11,  1.23s/it]\u001b[A\n",
            "Iteration:  87% 55/63 [01:07<00:09,  1.23s/it]\u001b[A\n",
            "Iteration:  89% 56/63 [01:09<00:08,  1.24s/it]\u001b[A\n",
            "Iteration:  90% 57/63 [01:10<00:07,  1.24s/it]\u001b[A\n",
            "Iteration:  92% 58/63 [01:11<00:06,  1.24s/it]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "\n",
            "Iteration:  94% 59/63 [01:12<00:04,  1.24s/it]\u001b[A\n",
            "Iteration:  95% 60/63 [01:14<00:03,  1.24s/it]\u001b[A\n",
            "Iteration:  97% 61/63 [01:15<00:02,  1.24s/it]\u001b[A\n",
            "Iteration:  98% 62/63 [01:16<00:01,  1.24s/it]\u001b[A\n",
            "Iteration: 100% 63/63 [01:17<00:00,  1.23s/it]\n",
            "Epoch:  80% 8/10 [10:08<02:33, 76.86s/it]\n",
            "Iteration:   0% 0/63 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   2% 1/63 [00:01<01:16,  1.23s/it]\u001b[A\n",
            "Iteration:   3% 2/63 [00:02<01:14,  1.23s/it]\u001b[A\n",
            "Iteration:   5% 3/63 [00:03<01:13,  1.23s/it]\u001b[A\n",
            "Iteration:   6% 4/63 [00:04<01:12,  1.23s/it]\u001b[A\n",
            "Iteration:   8% 5/63 [00:06<01:11,  1.23s/it]\u001b[A\n",
            "Iteration:  10% 6/63 [00:07<01:10,  1.23s/it]\u001b[A\n",
            "Iteration:  11% 7/63 [00:08<01:09,  1.23s/it]\u001b[A\n",
            "Iteration:  13% 8/63 [00:09<01:07,  1.23s/it]\u001b[A\n",
            "Iteration:  14% 9/63 [00:11<01:06,  1.24s/it]\u001b[A\n",
            "Iteration:  16% 10/63 [00:12<01:05,  1.24s/it]\u001b[A\n",
            "Iteration:  17% 11/63 [00:13<01:04,  1.23s/it]\u001b[A\n",
            "Iteration:  19% 12/63 [00:14<01:02,  1.23s/it]\u001b[A\n",
            "Iteration:  21% 13/63 [00:16<01:01,  1.23s/it]\u001b[A\n",
            "Iteration:  22% 14/63 [00:17<01:00,  1.23s/it]\u001b[A\n",
            "Iteration:  24% 15/63 [00:18<00:59,  1.23s/it]\u001b[A\n",
            "Iteration:  25% 16/63 [00:19<00:57,  1.23s/it]\u001b[A\n",
            "Iteration:  27% 17/63 [00:20<00:56,  1.23s/it]\u001b[A\n",
            "Iteration:  29% 18/63 [00:22<00:55,  1.23s/it]\u001b[A\n",
            "Iteration:  30% 19/63 [00:23<00:54,  1.23s/it]\u001b[A\n",
            "Iteration:  32% 20/63 [00:24<00:52,  1.23s/it]\u001b[A\n",
            "Iteration:  33% 21/63 [00:25<00:51,  1.23s/it]\u001b[A\n",
            "Iteration:  35% 22/63 [00:27<00:50,  1.23s/it]\u001b[A\n",
            "Iteration:  37% 23/63 [00:28<00:49,  1.23s/it]\u001b[A\n",
            "Iteration:  38% 24/63 [00:29<00:48,  1.24s/it]\u001b[A\n",
            "Iteration:  40% 25/63 [00:30<00:46,  1.23s/it]\u001b[A\n",
            "Iteration:  41% 26/63 [00:32<00:45,  1.23s/it]\u001b[A\n",
            "Iteration:  43% 27/63 [00:33<00:44,  1.23s/it]\u001b[A\n",
            "Iteration:  44% 28/63 [00:34<00:42,  1.23s/it]\u001b[A\n",
            "Iteration:  46% 29/63 [00:35<00:41,  1.23s/it]\u001b[A\n",
            "Iteration:  48% 30/63 [00:36<00:40,  1.23s/it]\u001b[A\n",
            "Iteration:  49% 31/63 [00:38<00:39,  1.23s/it]\u001b[A\n",
            "Iteration:  51% 32/63 [00:39<00:38,  1.23s/it]\u001b[A\n",
            "Iteration:  52% 33/63 [00:40<00:36,  1.23s/it]\u001b[A\n",
            "Iteration:  54% 34/63 [00:41<00:35,  1.23s/it]\u001b[A\n",
            "Iteration:  56% 35/63 [00:43<00:34,  1.23s/it]\u001b[A\n",
            "Iteration:  57% 36/63 [00:44<00:33,  1.23s/it]\u001b[A\n",
            "Iteration:  59% 37/63 [00:45<00:32,  1.23s/it]\u001b[A\n",
            "Iteration:  60% 38/63 [00:46<00:30,  1.23s/it]\u001b[A\n",
            "Iteration:  62% 39/63 [00:48<00:29,  1.23s/it]\u001b[A\n",
            "Iteration:  63% 40/63 [00:49<00:28,  1.23s/it]\u001b[A\n",
            "Iteration:  65% 41/63 [00:50<00:27,  1.23s/it]\u001b[A\n",
            "Iteration:  67% 42/63 [00:51<00:25,  1.23s/it]\u001b[A\n",
            "Iteration:  68% 43/63 [00:52<00:24,  1.23s/it]\u001b[A\n",
            "Iteration:  70% 44/63 [00:54<00:23,  1.23s/it]\u001b[A\n",
            "Iteration:  71% 45/63 [00:55<00:22,  1.23s/it]\u001b[A\n",
            "Iteration:  73% 46/63 [00:56<00:20,  1.23s/it]\u001b[A\n",
            "Iteration:  75% 47/63 [00:57<00:19,  1.23s/it]\u001b[A\n",
            "Iteration:  76% 48/63 [00:59<00:18,  1.23s/it]\u001b[A\n",
            "Iteration:  78% 49/63 [01:00<00:17,  1.23s/it]\u001b[A\n",
            "Iteration:  79% 50/63 [01:01<00:16,  1.23s/it]\u001b[A\n",
            "Iteration:  81% 51/63 [01:02<00:14,  1.24s/it]\u001b[A\n",
            "Iteration:  83% 52/63 [01:04<00:13,  1.24s/it]\u001b[A\n",
            "Iteration:  84% 53/63 [01:05<00:12,  1.24s/it]\u001b[A\n",
            "Iteration:  86% 54/63 [01:06<00:11,  1.24s/it]\u001b[A\n",
            "Iteration:  87% 55/63 [01:07<00:09,  1.23s/it]\u001b[A\n",
            "Iteration:  89% 56/63 [01:09<00:08,  1.23s/it]\u001b[A\n",
            "Iteration:  90% 57/63 [01:10<00:07,  1.23s/it]\u001b[A\n",
            "Iteration:  92% 58/63 [01:11<00:06,  1.23s/it]\u001b[A\n",
            "Iteration:  94% 59/63 [01:12<00:04,  1.23s/it]\u001b[A\n",
            "Iteration:  95% 60/63 [01:13<00:03,  1.23s/it]\u001b[A\n",
            "Iteration:  97% 61/63 [01:15<00:02,  1.23s/it]\u001b[A\n",
            "Iteration:  98% 62/63 [01:16<00:01,  1.23s/it]\u001b[A\n",
            "Iteration: 100% 63/63 [01:17<00:00,  1.22s/it]\n",
            "Epoch:  90% 9/10 [11:25<01:16, 76.94s/it]\n",
            "Iteration:   0% 0/63 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   2% 1/63 [00:01<01:16,  1.23s/it]\u001b[A\n",
            "Iteration:   3% 2/63 [00:02<01:14,  1.23s/it]\u001b[A\n",
            "Iteration:   5% 3/63 [00:03<01:13,  1.23s/it]\u001b[A\n",
            "Iteration:   6% 4/63 [00:04<01:12,  1.23s/it]\u001b[A\n",
            "Iteration:   8% 5/63 [00:06<01:11,  1.23s/it]\u001b[A\n",
            "Iteration:  10% 6/63 [00:07<01:10,  1.23s/it]\u001b[A\n",
            "Iteration:  11% 7/63 [00:08<01:09,  1.23s/it]\u001b[A\n",
            "Iteration:  13% 8/63 [00:09<01:07,  1.23s/it]\u001b[A\n",
            "Iteration:  14% 9/63 [00:11<01:06,  1.23s/it]\u001b[A\n",
            "Iteration:  16% 10/63 [00:12<01:05,  1.23s/it]\u001b[A\n",
            "Iteration:  17% 11/63 [00:13<01:04,  1.23s/it]\u001b[A\n",
            "Iteration:  19% 12/63 [00:14<01:02,  1.23s/it]\u001b[A\n",
            "Iteration:  21% 13/63 [00:16<01:01,  1.23s/it]\u001b[A\n",
            "Iteration:  22% 14/63 [00:17<01:00,  1.23s/it]\u001b[A\n",
            "Iteration:  24% 15/63 [00:18<00:59,  1.23s/it]\u001b[A\n",
            "Iteration:  25% 16/63 [00:19<00:57,  1.23s/it]\u001b[A\n",
            "Iteration:  27% 17/63 [00:20<00:56,  1.23s/it]\u001b[A\n",
            "Iteration:  29% 18/63 [00:22<00:55,  1.23s/it]\u001b[A\n",
            "Iteration:  30% 19/63 [00:23<00:54,  1.23s/it]\u001b[A\n",
            "Iteration:  32% 20/63 [00:24<00:53,  1.24s/it]\u001b[A\n",
            "Iteration:  33% 21/63 [00:25<00:51,  1.23s/it]\u001b[A\n",
            "Iteration:  35% 22/63 [00:27<00:50,  1.24s/it]\u001b[A\n",
            "Iteration:  37% 23/63 [00:28<00:49,  1.24s/it]\u001b[A\n",
            "Iteration:  38% 24/63 [00:29<00:48,  1.24s/it]\u001b[A\n",
            "Iteration:  40% 25/63 [00:30<00:47,  1.24s/it]\u001b[A\n",
            "Iteration:  41% 26/63 [00:32<00:45,  1.24s/it]\u001b[A\n",
            "Iteration:  43% 27/63 [00:33<00:44,  1.24s/it]\u001b[A\n",
            "Iteration:  44% 28/63 [00:34<00:43,  1.23s/it]\u001b[A\n",
            "Iteration:  46% 29/63 [00:35<00:41,  1.23s/it]\u001b[A\n",
            "Iteration:  48% 30/63 [00:37<00:40,  1.23s/it]\u001b[A\n",
            "Iteration:  49% 31/63 [00:38<00:39,  1.23s/it]\u001b[A\n",
            "Iteration:  51% 32/63 [00:39<00:38,  1.23s/it]\u001b[A\n",
            "Iteration:  52% 33/63 [00:40<00:37,  1.23s/it]\u001b[A\n",
            "Iteration:  54% 34/63 [00:41<00:35,  1.23s/it]\u001b[A\n",
            "Iteration:  56% 35/63 [00:43<00:34,  1.23s/it]\u001b[A\n",
            "Iteration:  57% 36/63 [00:44<00:33,  1.23s/it]\u001b[A\n",
            "Iteration:  59% 37/63 [00:45<00:32,  1.23s/it]\u001b[A\n",
            "Iteration:  60% 38/63 [00:46<00:30,  1.24s/it]\u001b[A\n",
            "Iteration:  62% 39/63 [00:48<00:29,  1.24s/it]\u001b[A\n",
            "Iteration:  63% 40/63 [00:49<00:28,  1.24s/it]\u001b[A\n",
            "Iteration:  65% 41/63 [00:50<00:27,  1.24s/it]\u001b[A\n",
            "Iteration:  67% 42/63 [00:51<00:25,  1.24s/it]\u001b[A\n",
            "Iteration:  68% 43/63 [00:53<00:24,  1.24s/it]\u001b[A\n",
            "Iteration:  70% 44/63 [00:54<00:23,  1.24s/it]\u001b[A\n",
            "Iteration:  71% 45/63 [00:55<00:22,  1.23s/it]\u001b[A\n",
            "Iteration:  73% 46/63 [00:56<00:20,  1.23s/it]\u001b[A\n",
            "Iteration:  75% 47/63 [00:57<00:19,  1.23s/it]\u001b[A\n",
            "Iteration:  76% 48/63 [00:59<00:18,  1.23s/it]\u001b[A\n",
            "Iteration:  78% 49/63 [01:00<00:17,  1.23s/it]\u001b[A\n",
            "Iteration:  79% 50/63 [01:01<00:16,  1.24s/it]\u001b[A\n",
            "Iteration:  81% 51/63 [01:02<00:14,  1.24s/it]\u001b[A\n",
            "Iteration:  83% 52/63 [01:04<00:13,  1.24s/it]\u001b[A\n",
            "Iteration:  84% 53/63 [01:05<00:12,  1.24s/it]\u001b[A\n",
            "Iteration:  86% 54/63 [01:06<00:11,  1.24s/it]\u001b[A\n",
            "Iteration:  87% 55/63 [01:07<00:09,  1.24s/it]\u001b[A\n",
            "Iteration:  89% 56/63 [01:09<00:08,  1.24s/it]\u001b[A\n",
            "Iteration:  90% 57/63 [01:10<00:07,  1.24s/it]\u001b[A\n",
            "Iteration:  92% 58/63 [01:11<00:06,  1.23s/it]\u001b[A\n",
            "Iteration:  94% 59/63 [01:12<00:04,  1.24s/it]\u001b[A\n",
            "Iteration:  95% 60/63 [01:14<00:03,  1.23s/it]\u001b[A\n",
            "Iteration:  97% 61/63 [01:15<00:02,  1.24s/it]\u001b[A\n",
            "Iteration:  98% 62/63 [01:16<00:01,  1.23s/it]\u001b[A\n",
            "Iteration: 100% 63/63 [01:17<00:00,  1.23s/it]\n",
            "Epoch: 100% 10/10 [12:43<00:00, 76.30s/it]\n",
            "04/18/2022 20:07:56 - INFO - __main__ -    global_step = 630, average loss = 0.11905004503501077\n",
            "04/18/2022 20:07:56 - INFO - __main__ -   Saving model checkpoint to /content/drive/MyDrive/TFM_Rosa-Maria/sequence-labelling/output/output-april-absa-categories-ten-bert/\n",
            "04/18/2022 20:07:56 - INFO - transformers.configuration_utils -   Configuration saved in /content/drive/MyDrive/TFM_Rosa-Maria/sequence-labelling/output/output-april-absa-categories-ten-bert/config.json\n",
            "04/18/2022 20:07:58 - INFO - transformers.modeling_utils -   Model weights saved in /content/drive/MyDrive/TFM_Rosa-Maria/sequence-labelling/output/output-april-absa-categories-ten-bert/pytorch_model.bin\n",
            "04/18/2022 20:07:58 - INFO - transformers.configuration_utils -   loading configuration file /content/drive/MyDrive/TFM_Rosa-Maria/sequence-labelling/output/output-april-absa-categories-ten-bert/config.json\n",
            "04/18/2022 20:07:58 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"_num_labels\": 25,\n",
            "  \"architectures\": [\n",
            "    \"BertForTokenClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": null,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"O\",\n",
            "    \"1\": \"I-SERVICE#GENERAL\",\n",
            "    \"2\": \"I-RESTAURANT#PRICES\",\n",
            "    \"3\": \"I-RESTAURANT#MISCELLANEOUS\",\n",
            "    \"4\": \"I-RESTAURANT#GENERAL\",\n",
            "    \"5\": \"I-LOCATION#GENERAL\",\n",
            "    \"6\": \"I-FOOD#STYLE_OPTIONS\",\n",
            "    \"7\": \"I-FOOD#QUALITY\",\n",
            "    \"8\": \"I-FOOD#PRICES\",\n",
            "    \"9\": \"I-DRINKS#STYLE_OPTIONS\",\n",
            "    \"10\": \"I-DRINKS#QUALITY\",\n",
            "    \"11\": \"I-DRINKS#PRICES\",\n",
            "    \"12\": \"I-AMBIENCE#GENERAL\",\n",
            "    \"13\": \"B-SERVICE#GENERAL\",\n",
            "    \"14\": \"B-RESTAURANT#PRICES\",\n",
            "    \"15\": \"B-RESTAURANT#MISCELLANEOUS\",\n",
            "    \"16\": \"B-RESTAURANT#GENERAL\",\n",
            "    \"17\": \"B-LOCATION#GENERAL\",\n",
            "    \"18\": \"B-FOOD#STYLE_OPTIONS\",\n",
            "    \"19\": \"B-FOOD#QUALITY\",\n",
            "    \"20\": \"B-FOOD#PRICES\",\n",
            "    \"21\": \"B-DRINKS#STYLE_OPTIONS\",\n",
            "    \"22\": \"B-DRINKS#QUALITY\",\n",
            "    \"23\": \"B-DRINKS#PRICES\",\n",
            "    \"24\": \"B-AMBIENCE#GENERAL\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"B-AMBIENCE#GENERAL\": 24,\n",
            "    \"B-DRINKS#PRICES\": 23,\n",
            "    \"B-DRINKS#QUALITY\": 22,\n",
            "    \"B-DRINKS#STYLE_OPTIONS\": 21,\n",
            "    \"B-FOOD#PRICES\": 20,\n",
            "    \"B-FOOD#QUALITY\": 19,\n",
            "    \"B-FOOD#STYLE_OPTIONS\": 18,\n",
            "    \"B-LOCATION#GENERAL\": 17,\n",
            "    \"B-RESTAURANT#GENERAL\": 16,\n",
            "    \"B-RESTAURANT#MISCELLANEOUS\": 15,\n",
            "    \"B-RESTAURANT#PRICES\": 14,\n",
            "    \"B-SERVICE#GENERAL\": 13,\n",
            "    \"I-AMBIENCE#GENERAL\": 12,\n",
            "    \"I-DRINKS#PRICES\": 11,\n",
            "    \"I-DRINKS#QUALITY\": 10,\n",
            "    \"I-DRINKS#STYLE_OPTIONS\": 9,\n",
            "    \"I-FOOD#PRICES\": 8,\n",
            "    \"I-FOOD#QUALITY\": 7,\n",
            "    \"I-FOOD#STYLE_OPTIONS\": 6,\n",
            "    \"I-LOCATION#GENERAL\": 5,\n",
            "    \"I-RESTAURANT#GENERAL\": 4,\n",
            "    \"I-RESTAURANT#MISCELLANEOUS\": 3,\n",
            "    \"I-RESTAURANT#PRICES\": 2,\n",
            "    \"I-SERVICE#GENERAL\": 1,\n",
            "    \"O\": 0\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "04/18/2022 20:07:58 - INFO - transformers.tokenization_utils -   Model name '/content/drive/MyDrive/TFM_Rosa-Maria/sequence-labelling/output/output-april-absa-categories-ten-bert/' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming '/content/drive/MyDrive/TFM_Rosa-Maria/sequence-labelling/output/output-april-absa-categories-ten-bert/' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "04/18/2022 20:07:58 - INFO - transformers.tokenization_utils -   Didn't find file /content/drive/MyDrive/TFM_Rosa-Maria/sequence-labelling/output/output-april-absa-categories-ten-bert/added_tokens.json. We won't load it.\n",
            "04/18/2022 20:07:58 - INFO - transformers.tokenization_utils -   loading file /content/drive/MyDrive/TFM_Rosa-Maria/sequence-labelling/output/output-april-absa-categories-ten-bert/vocab.txt\n",
            "04/18/2022 20:07:58 - INFO - transformers.tokenization_utils -   loading file None\n",
            "04/18/2022 20:07:58 - INFO - transformers.tokenization_utils -   loading file /content/drive/MyDrive/TFM_Rosa-Maria/sequence-labelling/output/output-april-absa-categories-ten-bert/special_tokens_map.json\n",
            "04/18/2022 20:07:58 - INFO - transformers.tokenization_utils -   loading file /content/drive/MyDrive/TFM_Rosa-Maria/sequence-labelling/output/output-april-absa-categories-ten-bert/tokenizer_config.json\n",
            "04/18/2022 20:07:58 - INFO - __main__ -   Evaluate the following checkpoints: ['/content/drive/MyDrive/TFM_Rosa-Maria/sequence-labelling/output/output-april-absa-categories-ten-bert/']\n",
            "04/18/2022 20:07:58 - INFO - transformers.configuration_utils -   loading configuration file /content/drive/MyDrive/TFM_Rosa-Maria/sequence-labelling/output/output-april-absa-categories-ten-bert/config.json\n",
            "04/18/2022 20:07:58 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"_num_labels\": 25,\n",
            "  \"architectures\": [\n",
            "    \"BertForTokenClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": null,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"O\",\n",
            "    \"1\": \"I-SERVICE#GENERAL\",\n",
            "    \"2\": \"I-RESTAURANT#PRICES\",\n",
            "    \"3\": \"I-RESTAURANT#MISCELLANEOUS\",\n",
            "    \"4\": \"I-RESTAURANT#GENERAL\",\n",
            "    \"5\": \"I-LOCATION#GENERAL\",\n",
            "    \"6\": \"I-FOOD#STYLE_OPTIONS\",\n",
            "    \"7\": \"I-FOOD#QUALITY\",\n",
            "    \"8\": \"I-FOOD#PRICES\",\n",
            "    \"9\": \"I-DRINKS#STYLE_OPTIONS\",\n",
            "    \"10\": \"I-DRINKS#QUALITY\",\n",
            "    \"11\": \"I-DRINKS#PRICES\",\n",
            "    \"12\": \"I-AMBIENCE#GENERAL\",\n",
            "    \"13\": \"B-SERVICE#GENERAL\",\n",
            "    \"14\": \"B-RESTAURANT#PRICES\",\n",
            "    \"15\": \"B-RESTAURANT#MISCELLANEOUS\",\n",
            "    \"16\": \"B-RESTAURANT#GENERAL\",\n",
            "    \"17\": \"B-LOCATION#GENERAL\",\n",
            "    \"18\": \"B-FOOD#STYLE_OPTIONS\",\n",
            "    \"19\": \"B-FOOD#QUALITY\",\n",
            "    \"20\": \"B-FOOD#PRICES\",\n",
            "    \"21\": \"B-DRINKS#STYLE_OPTIONS\",\n",
            "    \"22\": \"B-DRINKS#QUALITY\",\n",
            "    \"23\": \"B-DRINKS#PRICES\",\n",
            "    \"24\": \"B-AMBIENCE#GENERAL\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"B-AMBIENCE#GENERAL\": 24,\n",
            "    \"B-DRINKS#PRICES\": 23,\n",
            "    \"B-DRINKS#QUALITY\": 22,\n",
            "    \"B-DRINKS#STYLE_OPTIONS\": 21,\n",
            "    \"B-FOOD#PRICES\": 20,\n",
            "    \"B-FOOD#QUALITY\": 19,\n",
            "    \"B-FOOD#STYLE_OPTIONS\": 18,\n",
            "    \"B-LOCATION#GENERAL\": 17,\n",
            "    \"B-RESTAURANT#GENERAL\": 16,\n",
            "    \"B-RESTAURANT#MISCELLANEOUS\": 15,\n",
            "    \"B-RESTAURANT#PRICES\": 14,\n",
            "    \"B-SERVICE#GENERAL\": 13,\n",
            "    \"I-AMBIENCE#GENERAL\": 12,\n",
            "    \"I-DRINKS#PRICES\": 11,\n",
            "    \"I-DRINKS#QUALITY\": 10,\n",
            "    \"I-DRINKS#STYLE_OPTIONS\": 9,\n",
            "    \"I-FOOD#PRICES\": 8,\n",
            "    \"I-FOOD#QUALITY\": 7,\n",
            "    \"I-FOOD#STYLE_OPTIONS\": 6,\n",
            "    \"I-LOCATION#GENERAL\": 5,\n",
            "    \"I-RESTAURANT#GENERAL\": 4,\n",
            "    \"I-RESTAURANT#MISCELLANEOUS\": 3,\n",
            "    \"I-RESTAURANT#PRICES\": 2,\n",
            "    \"I-SERVICE#GENERAL\": 1,\n",
            "    \"O\": 0\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "04/18/2022 20:07:58 - INFO - transformers.modeling_utils -   loading weights file /content/drive/MyDrive/TFM_Rosa-Maria/sequence-labelling/output/output-april-absa-categories-ten-bert/pytorch_model.bin\n",
            "04/18/2022 20:08:02 - INFO - __main__ -   Creating features from dataset file at /content/drive/MyDrive/TFM_Rosa-Maria/sequence-labelling/data/categories/ABSA_data\n",
            "04/18/2022 20:08:02 - INFO - utils_ner -   Writing example 0 of 2000\n",
            "04/18/2022 20:08:02 - INFO - utils_ner -   *** Example ***\n",
            "04/18/2022 20:08:02 - INFO - utils_ner -   guid: dev-1\n",
            "04/18/2022 20:08:02 - INFO - utils_ner -   tokens: [CLS] [UNK] from previous posts this used to be a good place , but not any longer . [SEP]\n",
            "04/18/2022 20:08:02 - INFO - utils_ner -   input_ids: 101 100 2013 3025 8466 2023 2109 2000 2022 1037 2204 2173 1010 2021 2025 2151 2936 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 20:08:02 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 20:08:02 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 20:08:02 - INFO - utils_ner -   label_ids: -100 0 0 0 0 0 0 0 0 0 0 16 0 0 0 0 0 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "04/18/2022 20:08:02 - INFO - utils_ner -   *** Example ***\n",
            "04/18/2022 20:08:02 - INFO - utils_ner -   guid: dev-2\n",
            "04/18/2022 20:08:02 - INFO - utils_ner -   tokens: [CLS] [UNK] , there were four of us , arrived at noon - the place was empty - and the staff acted like we were imposing on them and they were very rude . [SEP]\n",
            "04/18/2022 20:08:02 - INFO - utils_ner -   input_ids: 101 100 1010 2045 2020 2176 1997 2149 1010 3369 2012 11501 1011 1996 2173 2001 4064 1011 1998 1996 3095 6051 2066 2057 2020 16625 2006 2068 1998 2027 2020 2200 12726 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 20:08:02 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 20:08:02 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 20:08:02 - INFO - utils_ner -   label_ids: -100 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 13 0 0 0 0 0 0 0 0 0 0 0 0 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "04/18/2022 20:08:02 - INFO - utils_ner -   *** Example ***\n",
            "04/18/2022 20:08:02 - INFO - utils_ner -   guid: dev-3\n",
            "04/18/2022 20:08:02 - INFO - utils_ner -   tokens: [CLS] [UNK] never brought us compliment ##ary noodles , ignored repeated requests for sugar , and threw our dishes on the table . [SEP]\n",
            "04/18/2022 20:08:02 - INFO - utils_ner -   input_ids: 101 100 2196 2716 2149 19394 5649 27130 1010 6439 5567 11186 2005 5699 1010 1998 4711 2256 10447 2006 1996 2795 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 20:08:02 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 20:08:02 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 20:08:02 - INFO - utils_ner -   label_ids: -100 0 0 0 0 0 -100 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "04/18/2022 20:08:02 - INFO - utils_ner -   *** Example ***\n",
            "04/18/2022 20:08:02 - INFO - utils_ner -   guid: dev-4\n",
            "04/18/2022 20:08:02 - INFO - utils_ner -   tokens: [CLS] [UNK] food was lou ##sy - too sweet or too salty and the portions tiny . [SEP]\n",
            "04/18/2022 20:08:02 - INFO - utils_ner -   input_ids: 101 100 2833 2001 10223 6508 1011 2205 4086 2030 2205 23592 1998 1996 8810 4714 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 20:08:02 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 20:08:02 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 20:08:02 - INFO - utils_ner -   label_ids: -100 0 19 0 0 -100 0 0 0 0 0 0 0 0 18 0 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "04/18/2022 20:08:02 - INFO - utils_ner -   *** Example ***\n",
            "04/18/2022 20:08:02 - INFO - utils_ner -   guid: dev-5\n",
            "04/18/2022 20:08:02 - INFO - utils_ner -   tokens: [CLS] [UNK] all that , they complained to me about the small tip . [SEP]\n",
            "04/18/2022 20:08:02 - INFO - utils_ner -   input_ids: 101 100 2035 2008 1010 2027 10865 2000 2033 2055 1996 2235 5955 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 20:08:02 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 20:08:02 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 20:08:02 - INFO - utils_ner -   label_ids: -100 0 0 0 0 0 0 0 0 0 0 0 0 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "04/18/2022 20:08:04 - INFO - __main__ -   Saving features into cached file /content/drive/MyDrive/TFM_Rosa-Maria/sequence-labelling/data/categories/ABSA_data/cached_dev_bert-base-uncased_128\n",
            "04/18/2022 20:08:04 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "04/18/2022 20:08:04 - INFO - __main__ -     Num examples = 2000\n",
            "04/18/2022 20:08:04 - INFO - __main__ -     Batch size = 8\n",
            "Evaluating: 100% 250/250 [00:30<00:00,  8.27it/s]\n",
            "04/18/2022 20:08:35 - INFO - __main__ -   ***** Eval results  *****\n",
            "04/18/2022 20:08:35 - INFO - __main__ -     accuracy = 0.9972664359861592\n",
            "04/18/2022 20:08:35 - INFO - __main__ -     f1 = 0.9665236051502146\n",
            "04/18/2022 20:08:35 - INFO - __main__ -     loss = 0.01332901188940741\n",
            "04/18/2022 20:08:35 - INFO - __main__ -     precision = 0.964041095890411\n",
            "04/18/2022 20:08:35 - INFO - __main__ -     recall = 0.9690189328743546\n",
            "04/18/2022 20:08:35 - INFO - transformers.configuration_utils -   loading configuration file /content/drive/MyDrive/TFM_Rosa-Maria/sequence-labelling/output/output-april-absa-categories-ten-bert/config.json\n",
            "04/18/2022 20:08:35 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"_num_labels\": 25,\n",
            "  \"architectures\": [\n",
            "    \"BertForTokenClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": null,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"O\",\n",
            "    \"1\": \"I-SERVICE#GENERAL\",\n",
            "    \"2\": \"I-RESTAURANT#PRICES\",\n",
            "    \"3\": \"I-RESTAURANT#MISCELLANEOUS\",\n",
            "    \"4\": \"I-RESTAURANT#GENERAL\",\n",
            "    \"5\": \"I-LOCATION#GENERAL\",\n",
            "    \"6\": \"I-FOOD#STYLE_OPTIONS\",\n",
            "    \"7\": \"I-FOOD#QUALITY\",\n",
            "    \"8\": \"I-FOOD#PRICES\",\n",
            "    \"9\": \"I-DRINKS#STYLE_OPTIONS\",\n",
            "    \"10\": \"I-DRINKS#QUALITY\",\n",
            "    \"11\": \"I-DRINKS#PRICES\",\n",
            "    \"12\": \"I-AMBIENCE#GENERAL\",\n",
            "    \"13\": \"B-SERVICE#GENERAL\",\n",
            "    \"14\": \"B-RESTAURANT#PRICES\",\n",
            "    \"15\": \"B-RESTAURANT#MISCELLANEOUS\",\n",
            "    \"16\": \"B-RESTAURANT#GENERAL\",\n",
            "    \"17\": \"B-LOCATION#GENERAL\",\n",
            "    \"18\": \"B-FOOD#STYLE_OPTIONS\",\n",
            "    \"19\": \"B-FOOD#QUALITY\",\n",
            "    \"20\": \"B-FOOD#PRICES\",\n",
            "    \"21\": \"B-DRINKS#STYLE_OPTIONS\",\n",
            "    \"22\": \"B-DRINKS#QUALITY\",\n",
            "    \"23\": \"B-DRINKS#PRICES\",\n",
            "    \"24\": \"B-AMBIENCE#GENERAL\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"B-AMBIENCE#GENERAL\": 24,\n",
            "    \"B-DRINKS#PRICES\": 23,\n",
            "    \"B-DRINKS#QUALITY\": 22,\n",
            "    \"B-DRINKS#STYLE_OPTIONS\": 21,\n",
            "    \"B-FOOD#PRICES\": 20,\n",
            "    \"B-FOOD#QUALITY\": 19,\n",
            "    \"B-FOOD#STYLE_OPTIONS\": 18,\n",
            "    \"B-LOCATION#GENERAL\": 17,\n",
            "    \"B-RESTAURANT#GENERAL\": 16,\n",
            "    \"B-RESTAURANT#MISCELLANEOUS\": 15,\n",
            "    \"B-RESTAURANT#PRICES\": 14,\n",
            "    \"B-SERVICE#GENERAL\": 13,\n",
            "    \"I-AMBIENCE#GENERAL\": 12,\n",
            "    \"I-DRINKS#PRICES\": 11,\n",
            "    \"I-DRINKS#QUALITY\": 10,\n",
            "    \"I-DRINKS#STYLE_OPTIONS\": 9,\n",
            "    \"I-FOOD#PRICES\": 8,\n",
            "    \"I-FOOD#QUALITY\": 7,\n",
            "    \"I-FOOD#STYLE_OPTIONS\": 6,\n",
            "    \"I-LOCATION#GENERAL\": 5,\n",
            "    \"I-RESTAURANT#GENERAL\": 4,\n",
            "    \"I-RESTAURANT#MISCELLANEOUS\": 3,\n",
            "    \"I-RESTAURANT#PRICES\": 2,\n",
            "    \"I-SERVICE#GENERAL\": 1,\n",
            "    \"O\": 0\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "04/18/2022 20:08:35 - INFO - transformers.tokenization_utils -   Model name '/content/drive/MyDrive/TFM_Rosa-Maria/sequence-labelling/output/output-april-absa-categories-ten-bert/' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming '/content/drive/MyDrive/TFM_Rosa-Maria/sequence-labelling/output/output-april-absa-categories-ten-bert/' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "04/18/2022 20:08:35 - INFO - transformers.tokenization_utils -   Didn't find file /content/drive/MyDrive/TFM_Rosa-Maria/sequence-labelling/output/output-april-absa-categories-ten-bert/added_tokens.json. We won't load it.\n",
            "04/18/2022 20:08:35 - INFO - transformers.tokenization_utils -   loading file /content/drive/MyDrive/TFM_Rosa-Maria/sequence-labelling/output/output-april-absa-categories-ten-bert/vocab.txt\n",
            "04/18/2022 20:08:35 - INFO - transformers.tokenization_utils -   loading file None\n",
            "04/18/2022 20:08:35 - INFO - transformers.tokenization_utils -   loading file /content/drive/MyDrive/TFM_Rosa-Maria/sequence-labelling/output/output-april-absa-categories-ten-bert/special_tokens_map.json\n",
            "04/18/2022 20:08:35 - INFO - transformers.tokenization_utils -   loading file /content/drive/MyDrive/TFM_Rosa-Maria/sequence-labelling/output/output-april-absa-categories-ten-bert/tokenizer_config.json\n",
            "04/18/2022 20:08:35 - INFO - transformers.configuration_utils -   loading configuration file /content/drive/MyDrive/TFM_Rosa-Maria/sequence-labelling/output/output-april-absa-categories-ten-bert/config.json\n",
            "04/18/2022 20:08:35 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"_num_labels\": 25,\n",
            "  \"architectures\": [\n",
            "    \"BertForTokenClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": null,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"O\",\n",
            "    \"1\": \"I-SERVICE#GENERAL\",\n",
            "    \"2\": \"I-RESTAURANT#PRICES\",\n",
            "    \"3\": \"I-RESTAURANT#MISCELLANEOUS\",\n",
            "    \"4\": \"I-RESTAURANT#GENERAL\",\n",
            "    \"5\": \"I-LOCATION#GENERAL\",\n",
            "    \"6\": \"I-FOOD#STYLE_OPTIONS\",\n",
            "    \"7\": \"I-FOOD#QUALITY\",\n",
            "    \"8\": \"I-FOOD#PRICES\",\n",
            "    \"9\": \"I-DRINKS#STYLE_OPTIONS\",\n",
            "    \"10\": \"I-DRINKS#QUALITY\",\n",
            "    \"11\": \"I-DRINKS#PRICES\",\n",
            "    \"12\": \"I-AMBIENCE#GENERAL\",\n",
            "    \"13\": \"B-SERVICE#GENERAL\",\n",
            "    \"14\": \"B-RESTAURANT#PRICES\",\n",
            "    \"15\": \"B-RESTAURANT#MISCELLANEOUS\",\n",
            "    \"16\": \"B-RESTAURANT#GENERAL\",\n",
            "    \"17\": \"B-LOCATION#GENERAL\",\n",
            "    \"18\": \"B-FOOD#STYLE_OPTIONS\",\n",
            "    \"19\": \"B-FOOD#QUALITY\",\n",
            "    \"20\": \"B-FOOD#PRICES\",\n",
            "    \"21\": \"B-DRINKS#STYLE_OPTIONS\",\n",
            "    \"22\": \"B-DRINKS#QUALITY\",\n",
            "    \"23\": \"B-DRINKS#PRICES\",\n",
            "    \"24\": \"B-AMBIENCE#GENERAL\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"B-AMBIENCE#GENERAL\": 24,\n",
            "    \"B-DRINKS#PRICES\": 23,\n",
            "    \"B-DRINKS#QUALITY\": 22,\n",
            "    \"B-DRINKS#STYLE_OPTIONS\": 21,\n",
            "    \"B-FOOD#PRICES\": 20,\n",
            "    \"B-FOOD#QUALITY\": 19,\n",
            "    \"B-FOOD#STYLE_OPTIONS\": 18,\n",
            "    \"B-LOCATION#GENERAL\": 17,\n",
            "    \"B-RESTAURANT#GENERAL\": 16,\n",
            "    \"B-RESTAURANT#MISCELLANEOUS\": 15,\n",
            "    \"B-RESTAURANT#PRICES\": 14,\n",
            "    \"B-SERVICE#GENERAL\": 13,\n",
            "    \"I-AMBIENCE#GENERAL\": 12,\n",
            "    \"I-DRINKS#PRICES\": 11,\n",
            "    \"I-DRINKS#QUALITY\": 10,\n",
            "    \"I-DRINKS#STYLE_OPTIONS\": 9,\n",
            "    \"I-FOOD#PRICES\": 8,\n",
            "    \"I-FOOD#QUALITY\": 7,\n",
            "    \"I-FOOD#STYLE_OPTIONS\": 6,\n",
            "    \"I-LOCATION#GENERAL\": 5,\n",
            "    \"I-RESTAURANT#GENERAL\": 4,\n",
            "    \"I-RESTAURANT#MISCELLANEOUS\": 3,\n",
            "    \"I-RESTAURANT#PRICES\": 2,\n",
            "    \"I-SERVICE#GENERAL\": 1,\n",
            "    \"O\": 0\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "04/18/2022 20:08:35 - INFO - transformers.modeling_utils -   loading weights file /content/drive/MyDrive/TFM_Rosa-Maria/sequence-labelling/output/output-april-absa-categories-ten-bert/pytorch_model.bin\n",
            "04/18/2022 20:08:39 - INFO - __main__ -   Creating features from dataset file at /content/drive/MyDrive/TFM_Rosa-Maria/sequence-labelling/data/categories/ABSA_data\n",
            "04/18/2022 20:08:39 - INFO - utils_ner -   Writing example 0 of 676\n",
            "04/18/2022 20:08:39 - INFO - utils_ner -   *** Example ***\n",
            "04/18/2022 20:08:39 - INFO - utils_ner -   guid: test-1\n",
            "04/18/2022 20:08:39 - INFO - utils_ner -   tokens: [CLS] [UNK] ! [SEP]\n",
            "04/18/2022 20:08:39 - INFO - utils_ner -   input_ids: 101 100 999 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 20:08:39 - INFO - utils_ner -   input_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 20:08:39 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 20:08:39 - INFO - utils_ner -   label_ids: -100 0 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "04/18/2022 20:08:39 - INFO - utils_ner -   *** Example ***\n",
            "04/18/2022 20:08:39 - INFO - utils_ner -   guid: test-2\n",
            "04/18/2022 20:08:39 - INFO - utils_ner -   tokens: [CLS] [UNK] really good su ##shi . [SEP]\n",
            "04/18/2022 20:08:39 - INFO - utils_ner -   input_ids: 101 100 2428 2204 10514 6182 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 20:08:39 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 20:08:39 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 20:08:39 - INFO - utils_ner -   label_ids: -100 0 0 0 19 -100 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "04/18/2022 20:08:39 - INFO - utils_ner -   *** Example ***\n",
            "04/18/2022 20:08:39 - INFO - utils_ner -   guid: test-3\n",
            "04/18/2022 20:08:39 - INFO - utils_ner -   tokens: [CLS] [UNK] the biggest portions but adequate . [SEP]\n",
            "04/18/2022 20:08:39 - INFO - utils_ner -   input_ids: 101 100 1996 5221 8810 2021 11706 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 20:08:39 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 20:08:39 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 20:08:39 - INFO - utils_ner -   label_ids: -100 0 0 0 18 0 0 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "04/18/2022 20:08:39 - INFO - utils_ner -   *** Example ***\n",
            "04/18/2022 20:08:39 - INFO - utils_ner -   guid: test-4\n",
            "04/18/2022 20:08:39 - INFO - utils_ner -   tokens: [CLS] [UNK] [UNK] cr ##eme br ##ule ##e is a must ! [SEP]\n",
            "04/18/2022 20:08:39 - INFO - utils_ner -   input_ids: 101 100 100 13675 21382 7987 9307 2063 2003 1037 2442 999 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 20:08:39 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 20:08:39 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 20:08:39 - INFO - utils_ner -   label_ids: -100 19 7 7 -100 7 -100 -100 0 0 0 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "04/18/2022 20:08:39 - INFO - utils_ner -   *** Example ***\n",
            "04/18/2022 20:08:39 - INFO - utils_ner -   guid: test-5\n",
            "04/18/2022 20:08:39 - INFO - utils_ner -   tokens: [CLS] [UNK] n ' t leave the restaurant without it . [SEP]\n",
            "04/18/2022 20:08:39 - INFO - utils_ner -   input_ids: 101 100 1050 1005 1056 2681 1996 4825 2302 2009 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 20:08:39 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 20:08:39 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/18/2022 20:08:39 - INFO - utils_ner -   label_ids: -100 0 0 -100 -100 0 0 0 0 0 0 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "04/18/2022 20:08:40 - INFO - __main__ -   Saving features into cached file /content/drive/MyDrive/TFM_Rosa-Maria/sequence-labelling/data/categories/ABSA_data/cached_test_bert-base-uncased_128\n",
            "04/18/2022 20:08:40 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "04/18/2022 20:08:40 - INFO - __main__ -     Num examples = 676\n",
            "04/18/2022 20:08:40 - INFO - __main__ -     Batch size = 8\n",
            "Evaluating: 100% 85/85 [00:09<00:00,  8.51it/s]\n",
            "04/18/2022 20:08:50 - INFO - __main__ -   ***** Eval results  *****\n",
            "04/18/2022 20:08:50 - INFO - __main__ -     accuracy = 0.9445281881217968\n",
            "04/18/2022 20:08:50 - INFO - __main__ -     f1 = 0.581704456606724\n",
            "04/18/2022 20:08:50 - INFO - __main__ -     loss = 0.2749962238047053\n",
            "04/18/2022 20:08:50 - INFO - __main__ -     precision = 0.5577211394302849\n",
            "04/18/2022 20:08:50 - INFO - __main__ -     recall = 0.6078431372549019\n"
          ]
        }
      ],
      "source": [
        "# change model_type and model_name_or_path to change transformer, e.g. roberta-base\n",
        "# https://huggingface.co/models\n",
        "\n",
        "# check that directory is correct for script, label, input and output\n",
        "!python /content/drive/MyDrive/TFM_Rosa-Maria/transformers-training-scripts/run_conll_ner.py --data_dir=/content/drive/MyDrive/TFM_Rosa-Maria/sequence-labelling/data/categories/original \\\n",
        "  --model_type bert-base-uncased \\\n",
        "  --labels /content/drive/MyDrive/TFM_Rosa-Maria/sequence-labelling/data/labels/categories-labels.txt \\\n",
        "  --model_name_or_path bert-base-uncased \\\n",
        "  --output_dir=/content/drive/MyDrive/TFM_Rosa-Maria/sequence-labelling/output/output-april-original-categories-bert-ten/ \\\n",
        "  --max_seq_length 128 \\\n",
        "  --num_train_epochs 10 \\\n",
        "  --per_gpu_train_batch_size 32 \\\n",
        "  --learning_rate 5e-5 \\\n",
        "  --save_steps 0 \\\n",
        "  --overwrite_cache \\\n",
        "  --overwrite_output_dir \\\n",
        "  --do_train \\\n",
        "  --do_eval \\\n",
        "  --do_predict \\"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "sl-transformers.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}